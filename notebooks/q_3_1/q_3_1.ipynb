{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the datasketch package is installed for running this notebook\n",
    "!pip install datasketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from src.preprocess import clean_html, clean_punctuation, clean_uppercase, clean_lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../../bigdata2023duplicatedetection/q_3_1/\"\n",
    "PATH_TO_TRAIN_DATA = BASE_PATH + \"data/train_q_3.1.csv\"\n",
    "PATH_TO_TEST_DATA = BASE_PATH + \"data/test_without_labels_q_3.1.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(PATH_TO_TRAIN_DATA, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, delimiter='\\n') \n",
    "    for row in reader:\n",
    "        data.append(row[0])  \n",
    "\n",
    "train_df = pd.DataFrame(data, columns=['Question'])\n",
    "train_df = train_df.drop(0)\n",
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(PATH_TO_TEST_DATA, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, delimiter='\\n') \n",
    "    for row in reader:\n",
    "        data.append(row[0])  \n",
    "\n",
    "test_df = pd.DataFrame(data, columns=['Question'])\n",
    "test_df = test_df.drop(0)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess - Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we implement a more streamlined preprocessing approach to the data, aiming to retain as much potentially valuable information as possible for effectively comparing the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, modify_columns):\n",
    "    df = clean_html(df, modify_columns)\n",
    "    print(\"HTML clean done\")\n",
    "\n",
    "    df = clean_punctuation(df, modify_columns)\n",
    "    print(\"Punctation clean done\")\n",
    "\n",
    "    df = clean_uppercase(df, modify_columns)\n",
    "    print(\"Uppercase clean done\")\n",
    "\n",
    "    df = clean_lemmatize(df, modify_columns)\n",
    "    print(\"Lemmatize done\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML clean done\n",
      "Punctation clean done\n",
      "Uppercase clean done\n",
      "Lemmatize done\n",
      "HTML clean done\n",
      "Punctation clean done\n",
      "Uppercase clean done\n",
      "Lemmatize done\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocess(train_df, [\"Question\"])\n",
    "test_df = preprocess(test_df, [\"Question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize documents using TF-IDF for computing cosine similarities\n",
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "X_tfidf = tfidf_vectorizer.fit_transform(train_df['Question'].tolist() + test_df['Question'].tolist())\n",
    "\n",
    "n_train = train_df.shape[0]\n",
    "X_train_tfidf = X_tfidf[:n_train]\n",
    "X_test_tfidf = X_tfidf[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sets of shingles (unique words) from question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Shingles'] = train_df['Question'].apply(lambda x: set(x.split()))\n",
    "test_df['Shingles'] = test_df['Question'].apply(lambda x: set(x.split()))\n",
    "train_shingles = train_df['Shingles'].tolist()\n",
    "test_shingles = test_df['Shingles'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Shingles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what be the step by step guide to invest in sh...</td>\n",
       "      <td>{be, in, india, to, invest, by, market, what, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what be the story of kohinoor kohinoor diamond</td>\n",
       "      <td>{be, kohinoor, story, diamond, what, of, the}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>{my, connection, i, use, vpn, while, increase,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why be i mentally very lonely how can i solve it</td>\n",
       "      <td>{be, i, why, solve, it, very, lonely, mentally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>{oxide, in, one, di, water, and, dissolve, sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>what type of diet can you follow to lose 5 pou...</td>\n",
       "      <td>{5, type, you, in, diet, pound, to, follow, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>which be the best commerce college in mangalore</td>\n",
       "      <td>{be, in, best, mangalore, which, college, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>be network a good field to have a career in wh...</td>\n",
       "      <td>{good, effective, proceed, a, if, career, yes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>can i use letter stamp a postcard stamp</td>\n",
       "      <td>{i, use, postcard, letter, stamp, a, can}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>how much water should a normal healthy adult d...</td>\n",
       "      <td>{normal, drink, healthy, avoid, adult, to, wat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "0     what be the step by step guide to invest in sh...   \n",
       "1        what be the story of kohinoor kohinoor diamond   \n",
       "2     how can i increase the speed of my internet co...   \n",
       "3      why be i mentally very lonely how can i solve it   \n",
       "4     which one dissolve in water quikly sugar salt ...   \n",
       "...                                                 ...   \n",
       "2995  what type of diet can you follow to lose 5 pou...   \n",
       "2996    which be the best commerce college in mangalore   \n",
       "2997  be network a good field to have a career in wh...   \n",
       "2998            can i use letter stamp a postcard stamp   \n",
       "2999  how much water should a normal healthy adult d...   \n",
       "\n",
       "                                               Shingles  \n",
       "0     {be, in, india, to, invest, by, market, what, ...  \n",
       "1         {be, kohinoor, story, diamond, what, of, the}  \n",
       "2     {my, connection, i, use, vpn, while, increase,...  \n",
       "3     {be, i, why, solve, it, very, lonely, mentally...  \n",
       "4     {oxide, in, one, di, water, and, dissolve, sug...  \n",
       "...                                                 ...  \n",
       "2995  {5, type, you, in, diet, pound, to, follow, 2,...  \n",
       "2996  {be, in, best, mangalore, which, college, the,...  \n",
       "2997  {good, effective, proceed, a, if, career, yes,...  \n",
       "2998          {i, use, postcard, letter, stamp, a, can}  \n",
       "2999  {normal, drink, healthy, avoid, adult, to, wat...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Shingles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what can someone do if theyve lose the wireles...</td>\n",
       "      <td>{wireless, their, someone, keyboard, if, logit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why india need to elect prime minister</td>\n",
       "      <td>{india, why, prime, to, minister, need, elect}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i make money online with free of cost</td>\n",
       "      <td>{online, i, with, make, money, can, of, how, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do mdma affect the first and high order moment...</td>\n",
       "      <td>{moment, affect, high, neuron, if, first, mdma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i be a saudi national and have sr 3 million in...</td>\n",
       "      <td>{with, advice, and, a, 20, approx, sr, possibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>whats your story</td>\n",
       "      <td>{whats, your, story}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>how do i know if a girl like me back or not</td>\n",
       "      <td>{not, me, i, if, or, a, how, back, girl, know,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>im gay how do i come out to my friend and family</td>\n",
       "      <td>{my, i, out, gay, to, come, and, family, how, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>wheaton college do gretchen dutschkeklotz rudi...</td>\n",
       "      <td>{craven, conservative, each, rudis, former, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>do girl see boy a boy do</td>\n",
       "      <td>{boy, a, see, girl, do}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0    what can someone do if theyve lose the wireles...   \n",
       "1               why india need to elect prime minister   \n",
       "2        how can i make money online with free of cost   \n",
       "3    do mdma affect the first and high order moment...   \n",
       "4    i be a saudi national and have sr 3 million in...   \n",
       "..                                                 ...   \n",
       "995                                   whats your story   \n",
       "996        how do i know if a girl like me back or not   \n",
       "997   im gay how do i come out to my friend and family   \n",
       "998  wheaton college do gretchen dutschkeklotz rudi...   \n",
       "999                           do girl see boy a boy do   \n",
       "\n",
       "                                              Shingles  \n",
       "0    {wireless, their, someone, keyboard, if, logit...  \n",
       "1       {india, why, prime, to, minister, need, elect}  \n",
       "2    {online, i, with, make, money, can, of, how, f...  \n",
       "3    {moment, affect, high, neuron, if, first, mdma...  \n",
       "4    {with, advice, and, a, 20, approx, sr, possibl...  \n",
       "..                                                 ...  \n",
       "995                               {whats, your, story}  \n",
       "996  {not, me, i, if, or, a, how, back, girl, know,...  \n",
       "997  {my, i, out, gay, to, come, and, family, how, ...  \n",
       "998  {craven, conservative, each, rudis, former, wh...  \n",
       "999                            {boy, a, see, girl, do}  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity for each pair of test and train documents\n",
    "# return query time, number of duplicates\n",
    "def exact_cosine_similarity(train_vectors, test_vectors):\n",
    "    start_time = time.time()\n",
    "    duplicates = 0\n",
    "\n",
    "    for test_vec in test_vectors:\n",
    "        similarities = cosine_similarity(test_vec, train_vectors)\n",
    "        if any(similarity >= 0.8 for similarity in similarities[0]):\n",
    "            duplicates += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    query_time = end_time - start_time\n",
    "    return duplicates, query_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Cosine Similarity found: 39 after 1.4869410991668701 secs\n"
     ]
    }
   ],
   "source": [
    "cosine_duplicates, cosine_query_time = exact_cosine_similarity(X_train_tfidf, X_test_tfidf)\n",
    "print(f\"Exact Cosine Similarity found: {cosine_duplicates} duplicates after {cosine_query_time} secs\")\n",
    "evaluation_results.append({\n",
    "        \"Type\": \"Exact-Cosine\",\n",
    "        \"BuildTime\": 0,\n",
    "        \"QueryTime\": cosine_query_time,\n",
    "        \"TotalTime\": cosine_query_time,\n",
    "        \"#Duplicates\": cosine_duplicates,\n",
    "        \"Parameters\": \"-\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns jaccard similarity of the given sets \n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute jaccard similarity for each pair of test and train documents\n",
    "# return query time, number of duplciates\n",
    "def exact_jaccard_similarity(train_docs, test_docs, threshold=0.8):\n",
    "    start_time = time.time()\n",
    "    duplicates = 0\n",
    "    for test_doc in test_docs:\n",
    "        for train_doc in train_docs:\n",
    "            sim = jaccard_similarity(test_doc, train_doc)\n",
    "            if sim > threshold:\n",
    "                duplicates += 1\n",
    "\n",
    "    return duplicates, time.time() - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Jaccard Similarity found: 34 after 3.991042137145996 secs\n"
     ]
    }
   ],
   "source": [
    "jaccard_duplicates, jaccard_query_time  = exact_jaccard_similarity(train_shingles, test_shingles)\n",
    "print(f\"Exact Jaccard Similarity found: {jaccard_duplicates} duplicates after {jaccard_query_time} secs\")\n",
    "evaluation_results.append({\n",
    "        \"Type\": \"Exact-Jaccard\",\n",
    "        \"BuildTime\": 0,\n",
    "        \"QueryTime\": jaccard_query_time,\n",
    "        \"TotalTime\": jaccard_query_time,\n",
    "        \"#Duplicates\": jaccard_duplicates,\n",
    "        \"Parameters\": \"-\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH with cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a matrix of random vectors from a normal distribution.\n",
    "def generate_random_vectors(dimensions, n_vectors):\n",
    "    return np.random.randn(dimensions, n_vectors)\n",
    "\n",
    "# Calculates the bin indices for vectors based \n",
    "# on their dot product with a set of random vectors.\n",
    "# Returns an array where each element corresponds to \n",
    "# the bin index of a vector in the training dataset.\n",
    "def get_bin_indices(X_vec, random_vectors):\n",
    "    bin_indices_bits = X_vec.dot(random_vectors) >= 0\n",
    "    powers_of_two = 1 << np.arange(random_vectors.shape[1] - 1, -1, -1)\n",
    "    return bin_indices_bits.dot(powers_of_two)\n",
    "\n",
    "# Trains a Locality Sensitive Hashing model \n",
    "# using cosine similarity for vector data.\n",
    "def train_cosine_lsh(X_train_vec, n_vectors):\n",
    "    # define random hyperplanes for hashing the vectors in the dataset.\n",
    "    random_vectors = generate_random_vectors(X_train_vec.shape[1], n_vectors)\n",
    "\n",
    "    # each vector in X_train_vec is hashed to a bin index based \n",
    "    # on its orientation relative to the random hyperplanes\n",
    "    bin_indices = get_bin_indices(X_train_vec, random_vectors)\n",
    "    \n",
    "    # Group the indices of vectors into the same bin based on their bin index\n",
    "    hash_table = defaultdict(list)\n",
    "    for idx, bin_idx in enumerate(bin_indices):\n",
    "        hash_table[bin_idx].append(idx)\n",
    "    \n",
    "    return hash_table, random_vectors\n",
    "\n",
    "# Queries the LSH model to find candidates similar \n",
    "# to a given query vector, based on cosine similarity.\n",
    "def query_cosine_lsh(hash_table, random_vectors, query_vector, X_train_vec, threshold=0.8):\n",
    "    bin_idx = get_bin_indices(query_vector, random_vectors)[0]\n",
    "    candidate_indices = hash_table.get(bin_idx, [])\n",
    "    \n",
    "    if not candidate_indices:\n",
    "        return []\n",
    "    \n",
    "    candidates = X_train_vec[candidate_indices]\n",
    "    similarities = cosine_similarity(query_vector, candidates).flatten()\n",
    "    \n",
    "    return [candidate_indices[i] for i, similarity in enumerate(similarities) if similarity > threshold]\n",
    "\n",
    "# Compute cosine similarity for each pair of test \n",
    "# and train documents using Locality Sensitive Hashing\n",
    "# return build time, query time, number of duplciates\n",
    "def cosine_lsh(X_train_vec, X_test_vec, K):\n",
    "    build_start = time.time()\n",
    "    hash_table, random_vectors = train_cosine_lsh(X_train_vec, K)\n",
    "    build_time = time.time() - build_start\n",
    "\n",
    "    query_start = time.time()\n",
    "    duplicates = 0\n",
    "    for i in range(X_test_vec.shape[0]):\n",
    "        similar_docs = query_cosine_lsh(hash_table, random_vectors, X_test_tfidf[i], X_train_vec, threshold=0.8)\n",
    "        if similar_docs:\n",
    "            duplicates += 1\n",
    "    query_time = time.time() - query_start\n",
    "\n",
    "    return duplicates, build_time, query_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_values = [i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b4c72abd2a47a78b9e19173bdc740a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LSH with cosine similarity:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cosine Similarity with LSH\n",
    "for K in tqdm(K_values, desc=\"LSH with cosine similarity\"):\n",
    "    duplicates, build_time, query_time = cosine_lsh(X_train_tfidf, X_test_tfidf, K)\n",
    "    evaluation_results.append({\n",
    "        \"Type\": \"LSH-Cosine\",\n",
    "        \"BuildTime\": build_time,\n",
    "        \"QueryTime\": query_time,\n",
    "        \"TotalTime\": build_time + query_time,\n",
    "        \"#Duplicates\": duplicates,\n",
    "        \"Parameters\": f\"K={K}\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH with jaccard distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minhash(doc_shingles, num_perm=128):\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for shingle in doc_shingles:\n",
    "        m.update(shingle.encode('utf8'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_lsh(train_data, test_data, num_perm):\n",
    "    # Create MinHashes\n",
    "    start_build_time = time.time()\n",
    "    lsh = MinHashLSH(threshold=0.8, num_perm=num_perm)\n",
    "    train_minhashes = [create_minhash(shingles, num_perm) for shingles in train_data]\n",
    "\n",
    "    for idx, minhash in enumerate(train_minhashes):\n",
    "        lsh.insert(idx, minhash)\n",
    "    build_time = time.time() - start_build_time\n",
    "\n",
    "    # Query LSH indexz\n",
    "    start_query_time = time.time()\n",
    "    duplicates = 0\n",
    "    for test_shingles in test_data:\n",
    "        test_minhash = create_minhash(test_shingles, num_perm)\n",
    "        candidate_idxs = lsh.query(test_minhash)\n",
    "        if candidate_idxs:\n",
    "            duplicates += 1\n",
    "    query_time = time.time() - start_query_time\n",
    "\n",
    "    return duplicates, build_time, query_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Similarity with LSH\n",
    "permutations = [16, 32, 64]\n",
    "for num_perm in permutations:\n",
    "    duplicates, build_time, query_time = jaccard_lsh(train_shingles, test_shingles, num_perm)\n",
    "    evaluation_results.append({\n",
    "        \"Type\": \"LSH-Jaccard\",\n",
    "        \"BuildTime\": build_time,\n",
    "        \"QueryTime\": query_time,\n",
    "        \"TotalTime\": build_time + query_time,\n",
    "        \"#Duplicates\": duplicates,\n",
    "        \"Parameters\": f\"Perm={num_perm}\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results in Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>BuildTime</th>\n",
       "      <th>QueryTime</th>\n",
       "      <th>TotalTime</th>\n",
       "      <th>#Duplicates</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exact-Cosine</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.486941</td>\n",
       "      <td>1.486941</td>\n",
       "      <td>39</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exact-Jaccard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.991042</td>\n",
       "      <td>3.991042</td>\n",
       "      <td>34</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>1.817030</td>\n",
       "      <td>1.819596</td>\n",
       "      <td>37</td>\n",
       "      <td>K=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>1.516204</td>\n",
       "      <td>1.517886</td>\n",
       "      <td>33</td>\n",
       "      <td>K=2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>1.133409</td>\n",
       "      <td>1.134567</td>\n",
       "      <td>29</td>\n",
       "      <td>K=3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>1.215225</td>\n",
       "      <td>1.216912</td>\n",
       "      <td>29</td>\n",
       "      <td>K=4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>1.129340</td>\n",
       "      <td>1.133116</td>\n",
       "      <td>28</td>\n",
       "      <td>K=5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>1.168320</td>\n",
       "      <td>1.172227</td>\n",
       "      <td>26</td>\n",
       "      <td>K=6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>1.383646</td>\n",
       "      <td>1.385362</td>\n",
       "      <td>30</td>\n",
       "      <td>K=7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>1.337832</td>\n",
       "      <td>1.341964</td>\n",
       "      <td>23</td>\n",
       "      <td>K=8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>1.276457</td>\n",
       "      <td>1.279013</td>\n",
       "      <td>23</td>\n",
       "      <td>K=9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSH-Cosine</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>1.205416</td>\n",
       "      <td>1.208281</td>\n",
       "      <td>23</td>\n",
       "      <td>K=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSH-Jaccard</td>\n",
       "      <td>1.457555</td>\n",
       "      <td>0.530722</td>\n",
       "      <td>1.988277</td>\n",
       "      <td>32</td>\n",
       "      <td>Perm=16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSH-Jaccard</td>\n",
       "      <td>2.128345</td>\n",
       "      <td>0.733924</td>\n",
       "      <td>2.862270</td>\n",
       "      <td>34</td>\n",
       "      <td>Perm=32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LSH-Jaccard</td>\n",
       "      <td>2.486950</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>3.206209</td>\n",
       "      <td>33</td>\n",
       "      <td>Perm=64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Type  BuildTime  QueryTime  TotalTime  #Duplicates Parameters\n",
       "0    Exact-Cosine   0.000000   1.486941   1.486941           39          -\n",
       "1   Exact-Jaccard   0.000000   3.991042   3.991042           34          -\n",
       "2      LSH-Cosine   0.002566   1.817030   1.819596           37        K=1\n",
       "3      LSH-Cosine   0.001682   1.516204   1.517886           33        K=2\n",
       "4      LSH-Cosine   0.001159   1.133409   1.134567           29        K=3\n",
       "5      LSH-Cosine   0.001687   1.215225   1.216912           29        K=4\n",
       "6      LSH-Cosine   0.003776   1.129340   1.133116           28        K=5\n",
       "7      LSH-Cosine   0.003907   1.168320   1.172227           26        K=6\n",
       "8      LSH-Cosine   0.001716   1.383646   1.385362           30        K=7\n",
       "9      LSH-Cosine   0.004131   1.337832   1.341964           23        K=8\n",
       "10     LSH-Cosine   0.002557   1.276457   1.279013           23        K=9\n",
       "11     LSH-Cosine   0.002865   1.205416   1.208281           23       K=10\n",
       "12    LSH-Jaccard   1.457555   0.530722   1.988277           32    Perm=16\n",
       "13    LSH-Jaccard   2.128345   0.733924   2.862270           34    Perm=32\n",
       "14    LSH-Jaccard   2.486950   0.719259   3.206209           33    Perm=64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exact Similarity Searches**:\n",
    "\n",
    "The Exact-Cosine method is faster than Exact-Jaccard. The number of duplicates found by Exact-Cosine is slightly higher (39) than that by Exact-Jaccard (34), indicating a possible difference in sensitivity to the data's similarity characteristics.\n",
    "\n",
    "**LSH with Cosine Similarity**:\n",
    "\n",
    "LSH-Cosine methods demonstrate varying performance with different K values (number of random projections). As K increases, there's a general trend towards faster query times until a certain point, after which the improvement plateaus. The build time is minimal across all K values, indicating efficient setup but varying effectiveness, with the highest number of duplicates found being 37 (at K=1) and the lowest being 23 (as K increases to 8, 9, and 10).\n",
    "The best balance between query time and number of duplicates found seems to occur at lower K values (e.g., K=1 or K=2), suggesting that fewer hash functions might be sufficient for this dataset under the cosine similarity measure. \n",
    "\n",
    "**LSH with Jaccard Similarity**:\n",
    "\n",
    "LSH-Jaccard methods show a significant increase in build time compared to LSH-Cosine, especially as the number of permutations increases. \n",
    "The query times for LSH-Jaccard are shorter than those for Exact-Jaccard, showcasing the efficiency gains from using LSH. The number of duplicates found is relatively consistent (32 to 34), which is competitive with the Exact-Jaccard method, indicating good effectiveness.\n",
    "There's a clear increase in total time as the number of permutations increases, suggesting diminishing returns on computational investment for higher Perm values.\n",
    "\n",
    "**Overall Observations**:\n",
    "\n",
    "LSH methods provide a flexible trade-off between computational efficiency and the accuracy of similarity searches.\n",
    "For cosine similarity, lower K values seem more effective, suggesting that a simpler model may suffice for this particular dataset.\n",
    "For Jaccard similarity, LSH significantly reduces query times compared to the exact method, with a modest increase in build time as the number of permutations increases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
