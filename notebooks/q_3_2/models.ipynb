{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:45:40.845826Z","iopub.status.busy":"2024-02-18T10:45:40.845065Z","iopub.status.idle":"2024-02-18T10:45:53.099225Z","shell.execute_reply":"2024-02-18T10:45:53.098158Z","shell.execute_reply.started":"2024-02-18T10:45:40.845792Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.5.0)\n","Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\n","Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.24.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\n","Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.1)\n","Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"]}],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T12:17:09.755803Z","iopub.status.busy":"2024-02-18T12:17:09.754861Z","iopub.status.idle":"2024-02-18T12:17:09.761847Z","shell.execute_reply":"2024-02-18T12:17:09.760900Z","shell.execute_reply.started":"2024-02-18T12:17:09.755767Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import numpy as np\n","from scipy.sparse import hstack\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from scipy.sparse import hstack, csr_matrix\n","import xgboost as xgb\n","import time\n","from sklearn.feature_extraction.text import CountVectorizer\n","import optuna\n","from sklearn.base import clone\n","import copy"]},{"cell_type":"markdown","metadata":{},"source":["Set paths to preprocessed train and test datasets \\\n","**Prerequisite**: run preprocess_extract_features.ipynb"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:08.666343Z","iopub.status.busy":"2024-02-18T10:46:08.665677Z","iopub.status.idle":"2024-02-18T10:46:08.670357Z","shell.execute_reply":"2024-02-18T10:46:08.669365Z","shell.execute_reply.started":"2024-02-18T10:46:08.666312Z"},"trusted":true},"outputs":[],"source":["PATH_TO_PREPROCESSED_TRAIN_DATA = \"../../bigdata2023duplicatedetection/q_3_2/preprocessed_data/preprocessed_train_df.pkl\"\n","PATH_TO_PREPROCESSED_TEST_DATA = \"../../bigdata2023duplicatedetection/q_3_2/preprocessed_data/preprocessed_test_df.pkl\""]},{"cell_type":"markdown","metadata":{},"source":["Set path where results will be saved as csv "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["PATH_TO_SAVE_RESULTS = \"../../results/q_3_2/predicted_labels.csv\""]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:10.606297Z","iopub.status.busy":"2024-02-18T10:46:10.605941Z","iopub.status.idle":"2024-02-18T10:46:11.092407Z","shell.execute_reply":"2024-02-18T10:46:11.091471Z","shell.execute_reply.started":"2024-02-18T10:46:10.606269Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_pickle(PATH_TO_PREPROCESSED_TRAIN_DATA)\n","test_df = pd.read_pickle(PATH_TO_PREPROCESSED_TEST_DATA)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:14.021795Z","iopub.status.busy":"2024-02-18T10:46:14.021430Z","iopub.status.idle":"2024-02-18T10:46:14.065942Z","shell.execute_reply":"2024-02-18T10:46:14.065056Z","shell.execute_reply.started":"2024-02-18T10:46:14.021768Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Question1</th>\n","      <th>Question2</th>\n","      <th>IsDuplicate</th>\n","      <th>cwc_min</th>\n","      <th>cwc_max</th>\n","      <th>csc_min</th>\n","      <th>csc_max</th>\n","      <th>ctc_min</th>\n","      <th>ctc_max</th>\n","      <th>...</th>\n","      <th>mean_len</th>\n","      <th>jaccard_sim</th>\n","      <th>word_overlap</th>\n","      <th>share_n_grams</th>\n","      <th>n_words_diff</th>\n","      <th>token_set_ratio</th>\n","      <th>token_sort_ratio</th>\n","      <th>fuzz_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>longest_substr_ratio</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>what be the step by step guide to invest in sh...</td>\n","      <td>what be the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>0.833333</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.916667</td>\n","      <td>0.785714</td>\n","      <td>...</td>\n","      <td>0.096296</td>\n","      <td>0.833333</td>\n","      <td>0.227273</td>\n","      <td>0.244186</td>\n","      <td>0.014925</td>\n","      <td>1.00</td>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>1.00</td>\n","      <td>0.982456</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>what be the story of kohinoor kohinoor diamond</td>\n","      <td>what would happen if the indian government ste...</td>\n","      <td>0</td>\n","      <td>0.666667</td>\n","      <td>0.250000</td>\n","      <td>0.666667</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.307692</td>\n","      <td>...</td>\n","      <td>0.077778</td>\n","      <td>0.222222</td>\n","      <td>0.090909</td>\n","      <td>0.034884</td>\n","      <td>0.074627</td>\n","      <td>0.81</td>\n","      <td>0.60</td>\n","      <td>0.62</td>\n","      <td>0.72</td>\n","      <td>0.553191</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>how can i increase the speed of my internet co...</td>\n","      <td>how can internet speed be increase by hack thr...</td>\n","      <td>0</td>\n","      <td>0.600000</td>\n","      <td>0.500000</td>\n","      <td>0.400000</td>\n","      <td>0.250000</td>\n","      <td>0.500000</td>\n","      <td>0.357143</td>\n","      <td>...</td>\n","      <td>0.088889</td>\n","      <td>0.375000</td>\n","      <td>0.136364</td>\n","      <td>0.011628</td>\n","      <td>0.014925</td>\n","      <td>0.73</td>\n","      <td>0.63</td>\n","      <td>0.37</td>\n","      <td>0.44</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>why be i mentally very lonely how can i solve it</td>\n","      <td>find the remainder when math2324math be divide...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.142857</td>\n","      <td>0.111111</td>\n","      <td>0.090909</td>\n","      <td>...</td>\n","      <td>0.074074</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.029851</td>\n","      <td>0.28</td>\n","      <td>0.25</td>\n","      <td>0.20</td>\n","      <td>0.26</td>\n","      <td>0.081633</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>which one dissolve in water quikly sugar salt ...</td>\n","      <td>which fish would survive in salt water</td>\n","      <td>0</td>\n","      <td>0.400000</td>\n","      <td>0.200000</td>\n","      <td>1.000000</td>\n","      <td>0.666667</td>\n","      <td>0.571429</td>\n","      <td>0.307692</td>\n","      <td>...</td>\n","      <td>0.074074</td>\n","      <td>0.153846</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","      <td>0.074627</td>\n","      <td>0.67</td>\n","      <td>0.47</td>\n","      <td>0.36</td>\n","      <td>0.55</td>\n","      <td>0.153846</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 23 columns</p>\n","</div>"],"text/plain":["   Id                                          Question1  \\\n","0   0  what be the step by step guide to invest in sh...   \n","1   1     what be the story of kohinoor kohinoor diamond   \n","2   2  how can i increase the speed of my internet co...   \n","3   3   why be i mentally very lonely how can i solve it   \n","4   4  which one dissolve in water quikly sugar salt ...   \n","\n","                                           Question2  IsDuplicate   cwc_min  \\\n","0  what be the step by step guide to invest in sh...            0  1.000000   \n","1  what would happen if the indian government ste...            0  0.666667   \n","2  how can internet speed be increase by hack thr...            0  0.600000   \n","3  find the remainder when math2324math be divide...            0  0.000000   \n","4             which fish would survive in salt water            0  0.400000   \n","\n","    cwc_max   csc_min   csc_max   ctc_min   ctc_max  ...  mean_len  \\\n","0  0.833333  1.000000  1.000000  0.916667  0.785714  ...  0.096296   \n","1  0.250000  0.666667  0.500000  0.500000  0.307692  ...  0.077778   \n","2  0.500000  0.400000  0.250000  0.500000  0.357143  ...  0.088889   \n","3  0.000000  0.250000  0.142857  0.111111  0.090909  ...  0.074074   \n","4  0.200000  1.000000  0.666667  0.571429  0.307692  ...  0.074074   \n","\n","   jaccard_sim  word_overlap  share_n_grams  n_words_diff  token_set_ratio  \\\n","0     0.833333      0.227273       0.244186      0.014925             1.00   \n","1     0.222222      0.090909       0.034884      0.074627             0.81   \n","2     0.375000      0.136364       0.011628      0.014925             0.73   \n","3     0.000000      0.000000       0.000000      0.029851             0.28   \n","4     0.153846      0.090909       0.000000      0.074627             0.67   \n","\n","   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n","0              0.93        0.93                1.00              0.982456  \n","1              0.60        0.62                0.72              0.553191  \n","2              0.63        0.37                0.44              0.181818  \n","3              0.25        0.20                0.26              0.081633  \n","4              0.47        0.36                0.55              0.153846  \n","\n","[5 rows x 23 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head(5)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:32.689219Z","iopub.status.busy":"2024-02-18T10:46:32.688310Z","iopub.status.idle":"2024-02-18T10:46:32.716631Z","shell.execute_reply":"2024-02-18T10:46:32.715793Z","shell.execute_reply.started":"2024-02-18T10:46:32.689183Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Question1</th>\n","      <th>Question2</th>\n","      <th>cwc_min</th>\n","      <th>cwc_max</th>\n","      <th>csc_min</th>\n","      <th>csc_max</th>\n","      <th>ctc_min</th>\n","      <th>ctc_max</th>\n","      <th>last_word_eq</th>\n","      <th>...</th>\n","      <th>mean_len</th>\n","      <th>jaccard_sim</th>\n","      <th>word_overlap</th>\n","      <th>share_n_grams</th>\n","      <th>n_words_diff</th>\n","      <th>token_set_ratio</th>\n","      <th>token_sort_ratio</th>\n","      <th>fuzz_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>longest_substr_ratio</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>283003</td>\n","      <td>what can someone do if theyve lose the wireles...</td>\n","      <td>what be the best usb wireless mouse that can b...</td>\n","      <td>0.428571</td>\n","      <td>0.333333</td>\n","      <td>0.50</td>\n","      <td>0.444444</td>\n","      <td>0.411765</td>\n","      <td>0.388889</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.129630</td>\n","      <td>0.230769</td>\n","      <td>0.136364</td>\n","      <td>0.000000</td>\n","      <td>0.029851</td>\n","      <td>0.67</td>\n","      <td>0.49</td>\n","      <td>0.46</td>\n","      <td>0.45</td>\n","      <td>0.131579</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>283004</td>\n","      <td>why india need to elect prime minister</td>\n","      <td>be prime minister of india elect or appoint</td>\n","      <td>0.800000</td>\n","      <td>0.800000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.571429</td>\n","      <td>0.500000</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.055556</td>\n","      <td>0.666667</td>\n","      <td>0.181818</td>\n","      <td>0.011628</td>\n","      <td>0.000000</td>\n","      <td>0.81</td>\n","      <td>0.67</td>\n","      <td>0.40</td>\n","      <td>0.42</td>\n","      <td>0.384615</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>283005</td>\n","      <td>how can i make money online with free of cost</td>\n","      <td>how can i make money online for free</td>\n","      <td>1.000000</td>\n","      <td>0.800000</td>\n","      <td>0.75</td>\n","      <td>0.600000</td>\n","      <td>0.875000</td>\n","      <td>0.700000</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.066667</td>\n","      <td>0.800000</td>\n","      <td>0.181818</td>\n","      <td>0.104651</td>\n","      <td>0.014925</td>\n","      <td>0.94</td>\n","      <td>0.84</td>\n","      <td>0.81</td>\n","      <td>0.89</td>\n","      <td>0.756757</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>283006</td>\n","      <td>do mdma affect the first and high order moment...</td>\n","      <td>do antipsychotic affect the first and high ord...</td>\n","      <td>0.909091</td>\n","      <td>0.909091</td>\n","      <td>1.00</td>\n","      <td>1.000000</td>\n","      <td>0.944444</td>\n","      <td>0.944444</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.133333</td>\n","      <td>0.833333</td>\n","      <td>0.454545</td>\n","      <td>0.337209</td>\n","      <td>0.000000</td>\n","      <td>0.97</td>\n","      <td>0.91</td>\n","      <td>0.93</td>\n","      <td>0.94</td>\n","      <td>0.919192</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>283007</td>\n","      <td>i be a saudi national and have sr 3 million in...</td>\n","      <td>where should i invest money to get high return</td>\n","      <td>0.200000</td>\n","      <td>0.062500</td>\n","      <td>0.50</td>\n","      <td>0.181818</td>\n","      <td>0.333333</td>\n","      <td>0.103448</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.140741</td>\n","      <td>0.050000</td>\n","      <td>0.045455</td>\n","      <td>0.000000</td>\n","      <td>0.164179</td>\n","      <td>0.39</td>\n","      <td>0.35</td>\n","      <td>0.24</td>\n","      <td>0.39</td>\n","      <td>0.170213</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 22 columns</p>\n","</div>"],"text/plain":["       Id                                          Question1  \\\n","0  283003  what can someone do if theyve lose the wireles...   \n","1  283004             why india need to elect prime minister   \n","2  283005      how can i make money online with free of cost   \n","3  283006  do mdma affect the first and high order moment...   \n","4  283007  i be a saudi national and have sr 3 million in...   \n","\n","                                           Question2   cwc_min   cwc_max  \\\n","0  what be the best usb wireless mouse that can b...  0.428571  0.333333   \n","1        be prime minister of india elect or appoint  0.800000  0.800000   \n","2               how can i make money online for free  1.000000  0.800000   \n","3  do antipsychotic affect the first and high ord...  0.909091  0.909091   \n","4     where should i invest money to get high return  0.200000  0.062500   \n","\n","   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  ...  mean_len  \\\n","0     0.50  0.444444  0.411765  0.388889           0.0  ...  0.129630   \n","1     0.00  0.000000  0.571429  0.500000           0.0  ...  0.055556   \n","2     0.75  0.600000  0.875000  0.700000           0.0  ...  0.066667   \n","3     1.00  1.000000  0.944444  0.944444           1.0  ...  0.133333   \n","4     0.50  0.181818  0.333333  0.103448           0.0  ...  0.140741   \n","\n","   jaccard_sim  word_overlap  share_n_grams  n_words_diff  token_set_ratio  \\\n","0     0.230769      0.136364       0.000000      0.029851             0.67   \n","1     0.666667      0.181818       0.011628      0.000000             0.81   \n","2     0.800000      0.181818       0.104651      0.014925             0.94   \n","3     0.833333      0.454545       0.337209      0.000000             0.97   \n","4     0.050000      0.045455       0.000000      0.164179             0.39   \n","\n","   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n","0              0.49        0.46                0.45              0.131579  \n","1              0.67        0.40                0.42              0.384615  \n","2              0.84        0.81                0.89              0.756757  \n","3              0.91        0.93                0.94              0.919192  \n","4              0.35        0.24                0.39              0.170213  \n","\n","[5 rows x 22 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["test_df.head(5)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:36.442979Z","iopub.status.busy":"2024-02-18T10:46:36.442151Z","iopub.status.idle":"2024-02-18T10:46:36.447500Z","shell.execute_reply":"2024-02-18T10:46:36.446614Z","shell.execute_reply.started":"2024-02-18T10:46:36.442949Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train_df shape: (283002, 23)\n","Test_df shape: (121287, 22)\n"]}],"source":["print(f\"Train_df shape: {train_df.shape}\")\n","print(f\"Test_df shape: {test_df.shape}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:49.439349Z","iopub.status.busy":"2024-02-18T10:46:49.438989Z","iopub.status.idle":"2024-02-18T10:46:49.510322Z","shell.execute_reply":"2024-02-18T10:46:49.509600Z","shell.execute_reply.started":"2024-02-18T10:46:49.439322Z"},"trusted":true},"outputs":[],"source":["y = train_df['IsDuplicate']\n","X = train_df[train_df.drop(columns=['Id', 'IsDuplicate']).columns.tolist()]"]},{"cell_type":"markdown","metadata":{},"source":["## K-Fold"]},{"cell_type":"markdown","metadata":{},"source":["The features corresponding to these names will be used among with features after applying vectorization of Question1 and Question2"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:51.543889Z","iopub.status.busy":"2024-02-18T10:46:51.543511Z","iopub.status.idle":"2024-02-18T10:46:51.594056Z","shell.execute_reply":"2024-02-18T10:46:51.593132Z","shell.execute_reply.started":"2024-02-18T10:46:51.543861Z"},"trusted":true},"outputs":[],"source":["extra_features_names = train_df.drop(columns=['Id', 'Question1', 'Question2', 'IsDuplicate']).columns.tolist()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:52.673863Z","iopub.status.busy":"2024-02-18T10:46:52.673176Z","iopub.status.idle":"2024-02-18T10:46:52.679050Z","shell.execute_reply":"2024-02-18T10:46:52.677937Z","shell.execute_reply.started":"2024-02-18T10:46:52.673830Z"},"trusted":true},"outputs":[],"source":["# Apply vectorization to train_q1, test_q1, train_q2, test_q2\n","def vectorize_questions(q1_vectorizer, q2_vectorizer, train_q1, test_q1, train_q2, test_q2):\n","    train_q1_vectors = q1_vectorizer.fit_transform(train_q1)\n","    test_q1_vectors = q1_vectorizer.transform(test_q1)\n","    \n","    train_q2_vectors = q2_vectorizer.fit_transform(train_q2)\n","    test_q2_vectors = q2_vectorizer.transform(test_q2)\n","    return train_q1_vectors, test_q1_vectors, train_q2_vectors, test_q2_vectors"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:54.195509Z","iopub.status.busy":"2024-02-18T10:46:54.195148Z","iopub.status.idle":"2024-02-18T10:46:54.208862Z","shell.execute_reply":"2024-02-18T10:46:54.207859Z","shell.execute_reply.started":"2024-02-18T10:46:54.195481Z"},"trusted":true},"outputs":[],"source":["def train_eval_model(model, X, y, vectorizer, extra_features, k=5, xgb_parameters=False):\n","    \"\"\"\n","    Trains and evaluates a machine learning model using k-fold cross-validation. The function supports\n","    both traditional sklearn models and XGBoost models. For XGBoost models, additional parameters can be\n","    passed through the `xgb_parameters` dictionary. The dataset is vectorized using the provided vectorizer,\n","    and additional features can be included.\n","\n","    Parameters:\n","    - model: The machine learning model to be trained. If `xgb_parameters` is provided, this model is ignored.\n","    - X: DataFrame containing the input features, must include 'Question1' and 'Question2' columns for vectorization.\n","    - y: Series or array-like containing the target variable.\n","    - vectorizer: The vectorizer to be used for transforming 'Question1' and 'Question2' into numerical features.\n","    - extra_features: Array-like or DataFrame containing additional features to be concatenated with the vectorized questions.\n","    - k: int, optional (default=5), The number of folds for k-fold cross-validation.\n","    - xgb_parameters: dict, optional (default=False), Parameters for training an XGBoost model. If False, the function\n","      uses the provided `model` parameter for training. If provided, it should include 'n_estimators' and any other\n","      XGBoost-specific parameters.\n","\n","    Returns:\n","    A tuple containing the mean accuracy, mean precision, mean recall, mean F1 score, and total training time across all folds.\n","    \"\"\"\n","    \n","    if xgb_parameters:\n","        n_estimators = xgb_parameters.get('n_estimators') \n","        xgb_parameters.pop('n_estimators')\n","        \n","    kf = KFold(n_splits=k, shuffle=True, random_state=21)\n","    for train_index, test_index in kf.split(X):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        extra_features_train, extra_features_test = extra_features[train_index], extra_features[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","        \n","        q1_vectorizer = clone(vectorizer)\n","        q2_vectorizer = clone(vectorizer)\n","        train_q1_vectors, test_q1_vectors, train_q2_vectors, test_q2_vectors = vectorize_questions(q1_vectorizer, q2_vectorizer, X_train['Question1'], \n","                                                                                                  X_test['Question1'], X_train['Question2'], X_test['Question2'])\n","        accuracies = []\n","        precisions = []\n","        recalls = []\n","        f1_scores = []\n","        start_time = time.time()\n","\n","        # Concatenate all features\n","        X_train_combined = hstack([train_q1_vectors, train_q2_vectors, extra_features_train])\n","        X_test_combined = hstack([test_q1_vectors, test_q2_vectors, extra_features_test])\n","\n","        if xgb_parameters:\n","            dtrain = xgb.DMatrix(X_train_combined, label=y_train)\n","            dvalid = xgb.DMatrix(X_test_combined, label=y_test)\n","            xgb_model = xgb.train(xgb_parameters, dtrain, num_boost_round=n_estimators, evals=[(dvalid, \"validation\")], \n","                                  early_stopping_rounds=10, verbose_eval=False)\n","            preds = xgb_model.predict(dvalid)\n","            y_pred = np.rint(preds)\n","        else:\n","            clf = clone(model)\n","            clf.fit(X_train_combined, y_train)\n","            y_pred = clf.predict(X_test_combined)\n","\n","        accuracies.append(accuracy_score(y_test, y_pred))\n","        precisions.append(precision_score(y_test, y_pred, average='macro'))\n","        recalls.append(recall_score(y_test, y_pred, average='macro'))\n","        f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n","\n","    total_time = time.time() - start_time\n","    mean_accuracy = np.mean(accuracies)\n","    mean_precision = np.mean(precisions)\n","    mean_recall = np.mean(recalls)\n","    mean_f1_score = np.mean(f1_scores)\n","    return mean_accuracy, mean_precision, mean_recall, mean_f1_score, total_time"]},{"cell_type":"markdown","metadata":{},"source":["Create a dictionary mapping weight factors to weighted_extra_features in order to experiment with diferrent weights later "]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:46:56.581194Z","iopub.status.busy":"2024-02-18T10:46:56.580846Z","iopub.status.idle":"2024-02-18T10:46:57.770890Z","shell.execute_reply":"2024-02-18T10:46:57.769943Z","shell.execute_reply.started":"2024-02-18T10:46:56.581168Z"},"trusted":true},"outputs":[],"source":["extra_features_names = train_df.drop(columns=['Id', 'Question1', 'Question2', 'IsDuplicate']).columns.tolist()\n","extra_features_weight_factors = [1, 1.5, 2, 3]\n","weighted_extra_features_sets={}\n","for weight_factor in extra_features_weight_factors:\n","    weighted_extra_features = X[extra_features_names] * weight_factor\n","    weighted_extra_features = csr_matrix(weighted_extra_features.to_numpy())\n","    weighted_extra_features_sets[weight_factor] = weighted_extra_features"]},{"cell_type":"markdown","metadata":{},"source":["We will try **Logistic Regression** and **XGBoost** using the features **Bag of Words (BoW)** and **TF-IDF** to evaluate them.\n","\n","**Logistic Regression**:\n","Logistic Regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible outcomes). It is used for binary classification tasks, where it models the probability that a given input belongs to a particular category (e.g., 0 or 1, true or false) based on a logistic function. It is a linear model, with the addition of a sigmoid function to convert linear output to a probability between 0 and 1.\n","\n","**XGBoost (Extreme Gradient Boosting)**:\n","XGBoost is an advanced implementation of gradient boosting algorithm, designed for speed and performance. It is a scalable and highly efficient end-to-end tree boosting system. XGBoost improves upon the base gradient boosting framework through system optimization and algorithm enhancements, including handling sparse data, tree pruning, and regularized learning to prevent overfitting. It is capable of performing both classification and regression tasks.\n","\n","We are going to evaluate and report the performance of every model + feature combination\n","with 5-fold Cross Validation using:\n","* Accuracy\n","* Precision\n","* Recall\n","* F1\n","* Training Time\n","\n","In order to evaluate the model performance we expirement with the hyperparameters of BoW method, TF-IDF method, Logistic Regression model and XGBoost Model. In order to find the optimal ones we use optuna:\\\n","A modern hyperparameter optimization framework that implements both grid search and more sophisticated algorithms like TPE (Tree-structured Parzen Estimator). It's designed for efficiency and ease of use, providing a flexible and clear interface for defining search spaces and optimization targets."]},{"cell_type":"markdown","metadata":{},"source":["The hyperparameters we experiment with are:\n","\n","**BoW Parameters**\n","* **max_df**: Limits the maximum frequency within the documents a given word can have to be considered\n","* **min_df**: Sets the minimum frequency a term must have to be included in the vocabulary\n","* **ngram_range**: Specifies the range of n-value for different n-grams to be extracted\n","* **max_features**: Limits the number of features to the top N features ordered by term frequency across the corpus\n","\n","**TF-IDF Parameters**\n","* **max_df**: This parameter is used to remove terms that appear too frequently\n","* **min_df**: This parameter is used to remove terms that appear too infrequently\n","* **ngram_range**: This specifies the range of n-grams to be extracted\n","* **norm**: The norm used to normalize term vectors\n","* **smooth_idf**: Smooths idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection\n","* **sublinear_tf**: Apply sublinear tf scaling, i.e., replace tf with 1 + log(tf)\n","* **max_features**: Limits the number of features to the top N features ordered by term frequency across the corpus\n","\n","**Logistic Regression Parameters**\n","* **C**: Controls the amount of shrinkage applied to the model\n","* **penalty**: Specifies the norm used in the penalization\n","* **class_weight**: Adjust weights inversely proportional to class frequencies in the input data\n","* **solver**: Algorithm to use in the optimization problem\n","* **max_iter**: Maximum number of iterations taken for the solvers to converge\n","\n","**XGBoost**\n","* **n_estimators**: It determines how many trees are built. Too few might underfit, while too many can lead to overfitting\n","* **max_depth**: Controls the depth of the trees. Deeper trees can model more complex patterns but also can lead to overfitting\n","* **learning_rate**: Determines the step size at each iteration while moving toward a minimum of a loss function\n","* **subsample**: The fraction of samples to be used for each tree\n","* **colsample_bytree**: The fraction of features to be used for each tree\n","\n","Additionally, we explored varying the weight factor applied to the extracted features, excluding the TF-IDF and BoW vectors. This involved adjusting the weight factor to modify the influence of these features in the model, apart from the primary text vectorization techniques."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:47:00.715578Z","iopub.status.busy":"2024-02-18T10:47:00.714957Z","iopub.status.idle":"2024-02-18T10:47:00.719605Z","shell.execute_reply":"2024-02-18T10:47:00.718611Z","shell.execute_reply.started":"2024-02-18T10:47:00.715535Z"},"trusted":true},"outputs":[],"source":["results=[]"]},{"cell_type":"markdown","metadata":{},"source":["# Logistic Regression with BoW"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T15:30:13.202098Z","iopub.status.busy":"2024-02-13T15:30:13.201725Z","iopub.status.idle":"2024-02-13T19:10:04.910205Z","shell.execute_reply":"2024-02-13T19:10:04.909194Z","shell.execute_reply.started":"2024-02-13T15:30:13.202069Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-02-13 15:30:13,209] A new study created in memory with name: no-name-300886eb-de6e-400c-9514-219533de74b7\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6be25a43b124867a2d84c9482c11959","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 15:32:25,005] Trial 0 finished with value: 0.8008565310492506 and parameters: {'max_df': 0.9250145097354617, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 14418, 'extra_features_weight_factor': 1, 'C': 0.1004377449272904, 'penalty': 'l2', 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 188}. Best is trial 0 with value: 0.8008565310492506.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 15:39:44,633] Trial 1 finished with value: 0.8078317467721077 and parameters: {'max_df': 0.8828411142505704, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 17422, 'extra_features_weight_factor': 1, 'C': 1.0286631341667167, 'penalty': 'l1', 'class_weight': None, 'max_iter': 330}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 15:48:48,687] Trial 2 finished with value: 0.7989166154302797 and parameters: {'max_df': 0.7515192410111597, 'min_df': 5, 'ngram_2': 4, 'bow_max_features': 19624, 'extra_features_weight_factor': 1.5, 'C': 3.042558559080279, 'penalty': 'l1', 'class_weight': None, 'max_iter': 374}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 15:56:10,514] Trial 3 finished with value: 0.7665846884474314 and parameters: {'max_df': 0.9462708422964814, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 16496, 'extra_features_weight_factor': 3, 'C': 0.001990212316999337, 'penalty': 'l2', 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 490}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:01:03,127] Trial 4 finished with value: 0.7995314520745437 and parameters: {'max_df': 0.7930023088813857, 'min_df': 3, 'ngram_2': 2, 'bow_max_features': 17158, 'extra_features_weight_factor': 1.5, 'C': 0.181320852311232, 'penalty': 'l1', 'class_weight': None, 'max_iter': 821}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:02:18,862] Trial 5 finished with value: 0.75076854580533 and parameters: {'max_df': 0.876775732676067, 'min_df': 4, 'ngram_2': 2, 'bow_max_features': 12715, 'extra_features_weight_factor': 3, 'C': 0.0007494306915828534, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 708}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:04:13,141] Trial 6 finished with value: 0.6924120677592385 and parameters: {'max_df': 0.7645754269249617, 'min_df': 4, 'ngram_2': 3, 'bow_max_features': 10997, 'extra_features_weight_factor': 1, 'C': 0.001411990886008604, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 696}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:05:55,223] Trial 7 finished with value: 0.6276316068437678 and parameters: {'max_df': 0.7281224865567089, 'min_df': 3, 'ngram_2': 3, 'bow_max_features': 17415, 'extra_features_weight_factor': 2, 'C': 2.7175862025882936e-05, 'penalty': 'l1', 'class_weight': None, 'max_iter': 287}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:08:38,551] Trial 8 finished with value: 0.6910657875209363 and parameters: {'max_df': 0.9472616212619236, 'min_df': 5, 'ngram_2': 4, 'bow_max_features': 14008, 'extra_features_weight_factor': 3, 'C': 0.0010783240567717534, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 769}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:15:27,206] Trial 9 finished with value: 0.8039519155341658 and parameters: {'max_df': 0.7142407657092962, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 15728, 'extra_features_weight_factor': 2, 'C': 1.0453816074110662, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 478}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:26:38,978] Trial 10 finished with value: 0.7904149087285602 and parameters: {'max_df': 0.8496547021993366, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 19887, 'extra_features_weight_factor': 1, 'C': 8.437189488312203, 'penalty': 'l1', 'class_weight': None, 'max_iter': 983}. Best is trial 1 with value: 0.8078317467721077.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:31:38,880] Trial 11 finished with value: 0.8079695549854772 and parameters: {'max_df': 0.7040892823952472, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 15943, 'extra_features_weight_factor': 2, 'C': 0.388773877161932, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 517}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:34:36,369] Trial 12 finished with value: 0.807174507600653 and parameters: {'max_df': 0.8855248150049375, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 18365, 'extra_features_weight_factor': 2, 'C': 0.06196190513972375, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 114}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:39:19,612] Trial 13 finished with value: 0.8050543812411219 and parameters: {'max_df': 0.8155177394569909, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 15122, 'extra_features_weight_factor': 2, 'C': 0.720599461810114, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 328}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:44:00,920] Trial 14 finished with value: 0.7634257001717303 and parameters: {'max_df': 0.8918548728800539, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 18138, 'extra_features_weight_factor': 1, 'C': 0.022644061194428532, 'penalty': 'l1', 'class_weight': None, 'max_iter': 578}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:47:27,188] Trial 15 finished with value: 0.8067186804333538 and parameters: {'max_df': 0.8398367337954193, 'min_df': 3, 'ngram_2': 2, 'bow_max_features': 13367, 'extra_features_weight_factor': 2, 'C': 0.4431370676198216, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 582}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 16:53:31,447] Trial 16 finished with value: 0.7902877011469883 and parameters: {'max_df': 0.8050383111403421, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 16104, 'extra_features_weight_factor': 1, 'C': 0.00935068442159744, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 390}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:02:06,379] Trial 17 finished with value: 0.7969448979159158 and parameters: {'max_df': 0.7738198111565597, 'min_df': 4, 'ngram_2': 3, 'bow_max_features': 11686, 'extra_features_weight_factor': 1.5, 'C': 3.8279074828881527, 'penalty': 'l1', 'class_weight': None, 'max_iter': 196}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:05:14,026] Trial 18 finished with value: 0.7892276379672228 and parameters: {'max_df': 0.8588261771326966, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 18472, 'extra_features_weight_factor': 1, 'C': 0.012650739609422848, 'penalty': 'l2', 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 442}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:06:14,010] Trial 19 finished with value: 0.6276316068437678 and parameters: {'max_df': 0.7004597980199825, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 15208, 'extra_features_weight_factor': 2, 'C': 2.706619703995508e-05, 'penalty': 'l1', 'class_weight': None, 'max_iter': 267}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:14:35,069] Trial 20 finished with value: 0.8036868997392245 and parameters: {'max_df': 0.9055961578579996, 'min_df': 3, 'ngram_2': 3, 'bow_max_features': 10131, 'extra_features_weight_factor': 2, 'C': 0.31825204296341264, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 635}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:17:26,954] Trial 21 finished with value: 0.8058494286259461 and parameters: {'max_df': 0.8767062614165133, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 18727, 'extra_features_weight_factor': 2, 'C': 0.047306651841524675, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 112}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:20:32,392] Trial 22 finished with value: 0.8073547183412131 and parameters: {'max_df': 0.9102135883146212, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 17296, 'extra_features_weight_factor': 2, 'C': 1.7868859754666255, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 130}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:24:37,556] Trial 23 finished with value: 0.8057752242033626 and parameters: {'max_df': 0.9037661128752484, 'min_df': 1, 'ngram_2': 3, 'bow_max_features': 17010, 'extra_features_weight_factor': 2, 'C': 2.168656693828978, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 219}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:30:58,438] Trial 24 finished with value: 0.8062098501070664 and parameters: {'max_df': 0.9202595677281497, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 17610, 'extra_features_weight_factor': 2, 'C': 0.7700357127974151, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 379}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:35:47,115] Trial 25 finished with value: 0.8049377742913477 and parameters: {'max_df': 0.8267297547633592, 'min_df': 3, 'ngram_2': 3, 'bow_max_features': 16480, 'extra_features_weight_factor': 1, 'C': 1.6067805950832785, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 283}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:47:32,686] Trial 26 finished with value: 0.7878071533063371 and parameters: {'max_df': 0.8611763259032363, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 19094, 'extra_features_weight_factor': 1.5, 'C': 7.3763354974240505, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 526}. Best is trial 11 with value: 0.8079695549854772.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:53:01,529] Trial 27 finished with value: 0.8097398604956856 and parameters: {'max_df': 0.9254521151171553, 'min_df': 3, 'ngram_2': 2, 'bow_max_features': 15655, 'extra_features_weight_factor': 3, 'C': 0.1648181388385525, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 427}. Best is trial 27 with value: 0.8097398604956856.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 17:58:40,833] Trial 28 finished with value: 0.7992240337524117 and parameters: {'max_df': 0.9329252391538257, 'min_df': 3, 'ngram_2': 2, 'bow_max_features': 14442, 'extra_features_weight_factor': 3, 'C': 0.17974368412997963, 'penalty': 'l1', 'class_weight': None, 'max_iter': 436}. Best is trial 27 with value: 0.8097398604956856.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:01:46,445] Trial 29 finished with value: 0.8041957300655119 and parameters: {'max_df': 0.7902545760666787, 'min_df': 4, 'ngram_2': 2, 'bow_max_features': 15549, 'extra_features_weight_factor': 3, 'C': 0.2077371641737866, 'penalty': 'l2', 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 627}. Best is trial 27 with value: 0.8097398604956856.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:08:16,369] Trial 30 finished with value: 0.7804609154705621 and parameters: {'max_df': 0.9286685365119814, 'min_df': 3, 'ngram_2': 2, 'bow_max_features': 14048, 'extra_features_weight_factor': 3, 'C': 0.004790755650081039, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 532}. Best is trial 27 with value: 0.8097398604956856.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:12:53,447] Trial 31 finished with value: 0.807481925922785 and parameters: {'max_df': 0.9070363734381807, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 16712, 'extra_features_weight_factor': 3, 'C': 0.07273753559944748, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 336}. Best is trial 27 with value: 0.8097398604956856.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:17:27,977] Trial 32 finished with value: 0.807757542349524 and parameters: {'max_df': 0.7397044144945459, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 16333, 'extra_features_weight_factor': 3, 'C': 0.07652706761183257, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 332}. Best is trial 27 with value: 0.8097398604956856.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:22:56,151] Trial 33 finished with value: 0.8010685436852036 and parameters: {'max_df': 0.7415619780447327, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 16018, 'extra_features_weight_factor': 3, 'C': 0.028299092766752517, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 421}. Best is trial 27 with value: 0.8097398604956856.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:27:28,248] Trial 34 finished with value: 0.8108741280980346 and parameters: {'max_df': 0.7300510548118829, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 17787, 'extra_features_weight_factor': 3, 'C': 0.1511698403377804, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 331}. Best is trial 34 with value: 0.8108741280980346.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:30:54,221] Trial 35 finished with value: 0.8107787224118558 and parameters: {'max_df': 0.7025093275558895, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 17803, 'extra_features_weight_factor': 3, 'C': 0.15866097044537372, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 488}. Best is trial 34 with value: 0.8108741280980346.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:34:20,368] Trial 36 finished with value: 0.8109377318888206 and parameters: {'max_df': 0.7026725408375757, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 19340, 'extra_features_weight_factor': 3, 'C': 0.15042289892477853, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 477}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:37:25,916] Trial 37 finished with value: 0.8058706298895414 and parameters: {'max_df': 0.7227372458391973, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 19188, 'extra_features_weight_factor': 3, 'C': 0.1631072781295116, 'penalty': 'l2', 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 469}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:38:36,759] Trial 38 finished with value: 0.7320266287870757 and parameters: {'max_df': 0.759252451938205, 'min_df': 5, 'ngram_2': 2, 'bow_max_features': 17927, 'extra_features_weight_factor': 3, 'C': 0.000247549492311072, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 396}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:40:36,328] Trial 39 finished with value: 0.8014607670617169 and parameters: {'max_df': 0.7329283980849165, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 19327, 'extra_features_weight_factor': 3, 'C': 0.026893740878836742, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 586}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:44:07,109] Trial 40 finished with value: 0.7692560476604405 and parameters: {'max_df': 0.7139268996483664, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 19863, 'extra_features_weight_factor': 3, 'C': 0.0030806647587049035, 'penalty': 'l2', 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 240}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:49:10,566] Trial 41 finished with value: 0.8072275107596413 and parameters: {'max_df': 0.7003955139807795, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 14585, 'extra_features_weight_factor': 3, 'C': 0.44242246000318963, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 541}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:52:20,135] Trial 42 finished with value: 0.8104077002989378 and parameters: {'max_df': 0.71337710856187, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 17784, 'extra_features_weight_factor': 3, 'C': 0.14521555697516636, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 490}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:55:41,863] Trial 43 finished with value: 0.8105349078805096 and parameters: {'max_df': 0.7175582764924363, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 17776, 'extra_features_weight_factor': 3, 'C': 0.14818694355055187, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 477}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 18:58:28,347] Trial 44 finished with value: 0.8094854453325419 and parameters: {'max_df': 0.7168155324955549, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 17833, 'extra_features_weight_factor': 3, 'C': 0.10622244321374816, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 483}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 19:00:14,917] Trial 45 finished with value: 0.7956940233637925 and parameters: {'max_df': 0.7465263714146342, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 18679, 'extra_features_weight_factor': 3, 'C': 0.014819420092290965, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 891}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 19:02:26,179] Trial 46 finished with value: 0.8045243496512392 and parameters: {'max_df': 0.7280489789864468, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 17028, 'extra_features_weight_factor': 3, 'C': 0.04736797130343949, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 676}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 19:05:13,446] Trial 47 finished with value: 0.8101002819768058 and parameters: {'max_df': 0.7125005594130907, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 18861, 'extra_features_weight_factor': 3, 'C': 0.1083008633420337, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 752}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 19:08:31,799] Trial 48 finished with value: 0.8099836750270316 and parameters: {'max_df': 0.754211843794511, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 18384, 'extra_features_weight_factor': 1.5, 'C': 0.2811121766619799, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 497}. Best is trial 36 with value: 0.8109377318888206.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-13 19:10:04,903] Trial 49 finished with value: 0.7873619267708355 and parameters: {'max_df': 0.7704193073215974, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 19396, 'extra_features_weight_factor': 3, 'C': 0.007315769213112299, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 349}. Best is trial 36 with value: 0.8109377318888206.\n"]}],"source":["def objective(trial):\n","    # Bow parameters\n","    max_df = trial.suggest_float('max_df', 0.7, 0.95)\n","    min_df = trial.suggest_int('min_df', 1, 5)  \n","    ngram_range = (1, trial.suggest_int('ngram_2', 2, 4))   \n","    bow_max_features = trial.suggest_int('bow_max_features', 10000, 20000)      \n","    vectorizer = CountVectorizer(max_df=max_df, min_df=min_df, ngram_range=ngram_range, max_features=bow_max_features)\n","\n","    extra_features_weight_factor = trial.suggest_categorical('extra_features_weight_factor', extra_features_weight_factors)\n","    extra_features = weighted_extra_features_sets[extra_features_weight_factor]\n","\n","    C = trial.suggest_float('C', 1e-5, 10.0, log=True)\n","    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n","    class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n","    solver = 'liblinear' if penalty == 'l1' else trial.suggest_categorical('solver', ['liblinear', 'saga'])\n","    max_iter = trial.suggest_int('max_iter', 100, 1000)\n","\n","    model = LogisticRegression(C=C, penalty=penalty, class_weight=class_weight, solver=solver, max_iter=max_iter, random_state=21, n_jobs=-1)\n","    accuracy, _, _, _, _ = train_eval_model(model, X, y, vectorizer, extra_features, k=3)\n","    return accuracy \n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=50, show_progress_bar=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T19:10:04.912081Z","iopub.status.busy":"2024-02-13T19:10:04.911791Z","iopub.status.idle":"2024-02-13T19:10:04.917648Z","shell.execute_reply":"2024-02-13T19:10:04.916584Z","shell.execute_reply.started":"2024-02-13T19:10:04.912057Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters for BoW with Logistic Regression: {'max_df': 0.7026725408375757, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 19340, 'extra_features_weight_factor': 3, 'C': 0.15042289892477853, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 477}\n"]}],"source":["best_params = study.best_params\n","print(\"Best parameters for BoW with Logistic Regression:\", best_params)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T19:10:04.919251Z","iopub.status.busy":"2024-02-13T19:10:04.918889Z","iopub.status.idle":"2024-02-13T19:16:40.476877Z","shell.execute_reply":"2024-02-13T19:16:40.475918Z","shell.execute_reply.started":"2024-02-13T19:10:04.919223Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]}],"source":["vectorizer = CountVectorizer(max_df=best_params[\"max_df\"], min_df=best_params[\"min_df\"], ngram_range=(1, best_params[\"ngram_2\"]), max_features=best_params[\"bow_max_features\"])\n","extra_features = weighted_extra_features_sets[best_params[\"extra_features_weight_factor\"]]\n","model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], class_weight=best_params['class_weight'], solver=best_params['solver'], max_iter=best_params['max_iter'], random_state=21, n_jobs=-1)\n","mean_accuracy, mean_precision, mean_recall, mean_f1_score, total_time = train_eval_model(model, X, y, vectorizer, extra_features, k=5)\n","results.append({\"Method\": \"Logistic Regression with BoW\", \"Accuracy\": mean_accuracy, \"Precision\": mean_precision, \"Recall\": mean_recall, \"F-Measure\": mean_f1_score})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LR_BoW_best_params = best_params"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T19:16:40.479559Z","iopub.status.busy":"2024-02-13T19:16:40.479292Z","iopub.status.idle":"2024-02-13T19:16:40.484861Z","shell.execute_reply":"2024-02-13T19:16:40.484041Z","shell.execute_reply.started":"2024-02-13T19:16:40.479536Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression Forest Model with BoW:\n","- Accuracy: 0.81\n","- Precision: 0.80\n","- Recall: 0.80\n","- F1: 0.80\n","- Total Time: 60.37\n"]}],"source":["print(\"Logistic Regression Forest Model with BoW:\")\n","print(f\"- Accuracy: {mean_accuracy:.2f}\")\n","print(f\"- Precision: {mean_precision:.2f}\")\n","print(f\"- Recall: {mean_recall:.2f}\")\n","print(f\"- F1: {mean_f1_score:.2f}\")\n","print(f\"- Total Time: {total_time:.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Logistic Regression with TF-IDF"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T06:11:17.751646Z","iopub.status.busy":"2024-02-14T06:11:17.750897Z","iopub.status.idle":"2024-02-14T10:57:00.754469Z","shell.execute_reply":"2024-02-14T10:57:00.753523Z","shell.execute_reply.started":"2024-02-14T06:11:17.751612Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-02-14 06:11:17,760] A new study created in memory with name: no-name-89af4475-2703-413f-890a-6882ae049aad\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24a58c5ac48648959513326150ef1b79","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:12:30,466] Trial 0 finished with value: 0.6988042487332246 and parameters: {'max_df': 0.9199435167279855, 'min_df': 2, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': False, 'max_features_tfidf': 13073, 'extra_features_weight_factor': 1, 'C': 0.005724052480584991, 'penalty': 'l2', 'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 870}. Best is trial 0 with value: 0.6988042487332246.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:14:54,842] Trial 1 finished with value: 0.794358343757288 and parameters: {'max_df': 0.8941482856316219, 'min_df': 2, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 14104, 'extra_features_weight_factor': 1.5, 'C': 0.13786912219363018, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 971}. Best is trial 1 with value: 0.794358343757288.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:18:44,153] Trial 2 finished with value: 0.7878177539381347 and parameters: {'max_df': 0.8171987577616154, 'min_df': 2, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 11671, 'extra_features_weight_factor': 3, 'C': 1.1515274992320799, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 603}. Best is trial 1 with value: 0.794358343757288.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:28:46,739] Trial 3 finished with value: 0.8006975215722857 and parameters: {'max_df': 0.9004696444200713, 'min_df': 1, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 19687, 'extra_features_weight_factor': 2, 'C': 6.1962070029410805, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 749}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:30:32,884] Trial 4 finished with value: 0.6941611720058516 and parameters: {'max_df': 0.8828169422446907, 'min_df': 5, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 16975, 'extra_features_weight_factor': 1.5, 'C': 0.00021609654613261468, 'penalty': 'l2', 'class_weight': None, 'solver': 'liblinear', 'max_iter': 109}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:31:37,314] Trial 5 finished with value: 0.6793520893845273 and parameters: {'max_df': 0.852752416608433, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 18658, 'extra_features_weight_factor': 2, 'C': 0.0006525210787958934, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 353}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:35:25,602] Trial 6 finished with value: 0.7967010833845697 and parameters: {'max_df': 0.7435728725447797, 'min_df': 2, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 15492, 'extra_features_weight_factor': 1, 'C': 2.692801090805718, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 193}. Best is trial 3 with value: 0.8006975215722857.\n","[I 2024-02-14 06:39:52,666] Trial 7 finished with value: 0.787531536879598 and parameters: {'max_df': 0.7208977423738201, 'min_df': 4, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 12270, 'extra_features_weight_factor': 1, 'C': 0.10911019028199953, 'penalty': 'l2', 'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 527}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:47:34,234] Trial 8 finished with value: 0.7972841181334408 and parameters: {'max_df': 0.7974122265226217, 'min_df': 5, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 10237, 'extra_features_weight_factor': 1.5, 'C': 1.0972709780321779, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 160}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:52:30,066] Trial 9 finished with value: 0.7436025187101151 and parameters: {'max_df': 0.7602329540604393, 'min_df': 4, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 17030, 'extra_features_weight_factor': 1, 'C': 0.057230528648159334, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 716}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 06:53:29,912] Trial 10 finished with value: 0.6276316068437678 and parameters: {'max_df': 0.9434424850401708, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 19911, 'extra_features_weight_factor': 2, 'C': 3.389843151646095e-05, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 772}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:04:01,791] Trial 11 finished with value: 0.7921958148705663 and parameters: {'max_df': 0.8023526879831568, 'min_df': 5, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 10119, 'extra_features_weight_factor': 1.5, 'C': 9.754136491389506, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 327}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:11:14,757] Trial 12 finished with value: 0.7962982593762589 and parameters: {'max_df': 0.7764505818507839, 'min_df': 1, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 15547, 'extra_features_weight_factor': 2, 'C': 0.6960625222268066, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 521}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:20:59,472] Trial 13 finished with value: 0.795460809464244 and parameters: {'max_df': 0.8460221041219045, 'min_df': 4, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': False, 'max_features_tfidf': 10789, 'extra_features_weight_factor': 3, 'C': 7.0901325357678004, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 373}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:23:28,178] Trial 14 finished with value: 0.7055992537155215 and parameters: {'max_df': 0.7930211109348145, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 18120, 'extra_features_weight_factor': 1.5, 'C': 0.010170103087195017, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 685}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:29:58,310] Trial 15 finished with value: 0.7608073441177094 and parameters: {'max_df': 0.8654318546128268, 'min_df': 3, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 13977, 'extra_features_weight_factor': 2, 'C': 0.4784554895475713, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 448}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:34:11,186] Trial 16 finished with value: 0.7178111815464202 and parameters: {'max_df': 0.7002208013915862, 'min_df': 5, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 19885, 'extra_features_weight_factor': 1.5, 'C': 0.02166504731143696, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 838}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:41:25,910] Trial 17 finished with value: 0.794262938071109 and parameters: {'max_df': 0.8309500544688843, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 16540, 'extra_features_weight_factor': 2, 'C': 1.987475807976533, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 224}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:47:56,012] Trial 18 finished with value: 0.7845739606080523 and parameters: {'max_df': 0.9032118895920013, 'min_df': 4, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 14319, 'extra_features_weight_factor': 3, 'C': 0.24431450029332127, 'penalty': 'l1', 'class_weight': None, 'max_iter': 605}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:50:12,769] Trial 19 finished with value: 0.6858502766764899 and parameters: {'max_df': 0.936566853635318, 'min_df': 5, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 18564, 'extra_features_weight_factor': 1.5, 'C': 0.002011476693943901, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 988}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 07:59:03,428] Trial 20 finished with value: 0.7985031907901711 and parameters: {'max_df': 0.8707246277452617, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 12781, 'extra_features_weight_factor': 2, 'C': 3.6683872328800016, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 114}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 08:07:59,353] Trial 21 finished with value: 0.7974219263468103 and parameters: {'max_df': 0.8694063535802163, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 11610, 'extra_features_weight_factor': 2, 'C': 3.7758424020291783, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 139}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 08:16:57,169] Trial 22 finished with value: 0.7979201560413001 and parameters: {'max_df': 0.8742408476996748, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 12159, 'extra_features_weight_factor': 2, 'C': 3.710742856539992, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 267}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 08:27:32,554] Trial 23 finished with value: 0.7933088812093201 and parameters: {'max_df': 0.9129914722813903, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 12983, 'extra_features_weight_factor': 2, 'C': 9.705944759059934, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 241}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 08:33:41,589] Trial 24 finished with value: 0.7898106727160938 and parameters: {'max_df': 0.8828373827066209, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 13022, 'extra_features_weight_factor': 2, 'C': 0.39766970268613894, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 286}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 08:42:21,720] Trial 25 finished with value: 0.798630398371743 and parameters: {'max_df': 0.8402037457674014, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 11468, 'extra_features_weight_factor': 2, 'C': 2.8463289982762774, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 272}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 08:46:11,842] Trial 26 finished with value: 0.7193270718934849 and parameters: {'max_df': 0.8317242045983848, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 11090, 'extra_features_weight_factor': 2, 'C': 0.061182690190191936, 'penalty': 'l1', 'class_weight': 'balanced', 'max_iter': 406}. Best is trial 3 with value: 0.8006975215722857.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 08:53:59,477] Trial 27 finished with value: 0.8063900608476265 and parameters: {'max_df': 0.8516229056978248, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 13668, 'extra_features_weight_factor': 2, 'C': 1.6089788731451606, 'penalty': 'l1', 'class_weight': None, 'max_iter': 449}. Best is trial 27 with value: 0.8063900608476265.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 08:54:58,913] Trial 28 finished with value: 0.6276316068437678 and parameters: {'max_df': 0.8486441946171666, 'min_df': 2, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 15086, 'extra_features_weight_factor': 2, 'C': 1.1263432370203035e-05, 'penalty': 'l1', 'class_weight': None, 'max_iter': 439}. Best is trial 27 with value: 0.8063900608476265.\n","[I 2024-02-14 08:59:39,786] Trial 29 finished with value: 0.7907647295778828 and parameters: {'max_df': 0.9277776297696372, 'min_df': 2, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 13771, 'extra_features_weight_factor': 2, 'C': 1.2407555934065209, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 902}. Best is trial 27 with value: 0.8063900608476265.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 09:05:16,430] Trial 30 finished with value: 0.7843089448131109 and parameters: {'max_df': 0.9122476910741082, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 13503, 'extra_features_weight_factor': 2, 'C': 0.21811741583158872, 'penalty': 'l1', 'class_weight': None, 'max_iter': 618}. Best is trial 27 with value: 0.8063900608476265.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 09:14:16,909] Trial 31 finished with value: 0.803178069412937 and parameters: {'max_df': 0.815858531116743, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 12396, 'extra_features_weight_factor': 2, 'C': 3.3958482629238746, 'penalty': 'l1', 'class_weight': None, 'max_iter': 186}. Best is trial 27 with value: 0.8063900608476265.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 09:22:34,739] Trial 32 finished with value: 0.8060084381029109 and parameters: {'max_df': 0.819711455987925, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 14697, 'extra_features_weight_factor': 2, 'C': 1.9953630451876583, 'penalty': 'l1', 'class_weight': None, 'max_iter': 486}. Best is trial 27 with value: 0.8063900608476265.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 09:29:13,565] Trial 33 finished with value: 0.803517289630462 and parameters: {'max_df': 0.8171747305334653, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 14251, 'extra_features_weight_factor': 2, 'C': 0.7395830659729348, 'penalty': 'l1', 'class_weight': None, 'max_iter': 469}. Best is trial 27 with value: 0.8063900608476265.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 09:35:15,141] Trial 34 finished with value: 0.8076303347679522 and parameters: {'max_df': 0.8149653602393341, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 14479, 'extra_features_weight_factor': 3, 'C': 0.735800354813108, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 473}. Best is trial 34 with value: 0.8076303347679522.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 09:41:37,199] Trial 35 finished with value: 0.7750227913583649 and parameters: {'max_df': 0.8161203650509772, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 14496, 'extra_features_weight_factor': 3, 'C': 0.031414992918531996, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 504}. Best is trial 34 with value: 0.8076303347679522.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 09:47:46,848] Trial 36 finished with value: 0.8079483537218818 and parameters: {'max_df': 0.7806064669447217, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 16282, 'extra_features_weight_factor': 3, 'C': 0.7065566962380841, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 479}. Best is trial 36 with value: 0.8079483537218818.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 09:54:54,129] Trial 37 finished with value: 0.7946869633430153 and parameters: {'max_df': 0.7720832626021882, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 16148, 'extra_features_weight_factor': 3, 'C': 0.12841770581078307, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 577}. Best is trial 36 with value: 0.8079483537218818.\n","[I 2024-02-14 10:01:47,736] Trial 38 finished with value: 0.803485487735069 and parameters: {'max_df': 0.7835592284296398, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 14770, 'extra_features_weight_factor': 3, 'C': 0.3341589929740676, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 667}. Best is trial 36 with value: 0.8079483537218818.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:07:03,138] Trial 39 finished with value: 0.8086903979477177 and parameters: {'max_df': 0.7590369630639975, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 16103, 'extra_features_weight_factor': 3, 'C': 0.9241048121016162, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 401}. Best is trial 39 with value: 0.8086903979477177.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:12:20,013] Trial 40 finished with value: 0.7406661437021647 and parameters: {'max_df': 0.7525502741366124, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 17690, 'extra_features_weight_factor': 3, 'C': 0.005287294371958565, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 393}. Best is trial 39 with value: 0.8086903979477177.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:18:27,961] Trial 41 finished with value: 0.8084465834163717 and parameters: {'max_df': 0.7352626576177363, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 15487, 'extra_features_weight_factor': 3, 'C': 1.5530014003759842, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 475}. Best is trial 39 with value: 0.8086903979477177.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:23:57,083] Trial 42 finished with value: 0.8086691966841224 and parameters: {'max_df': 0.7329615350681864, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 15748, 'extra_features_weight_factor': 3, 'C': 1.1720252924743748, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 414}. Best is trial 39 with value: 0.8086903979477177.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:28:42,423] Trial 43 finished with value: 0.8081815676214302 and parameters: {'max_df': 0.7327316489888404, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 16185, 'extra_features_weight_factor': 3, 'C': 0.7672318084555475, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 342}. Best is trial 39 with value: 0.8086903979477177.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:33:14,886] Trial 44 finished with value: 0.7978565522505141 and parameters: {'max_df': 0.7328779804234051, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 15791, 'extra_features_weight_factor': 3, 'C': 0.16716703237047684, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 327}. Best is trial 39 with value: 0.8086903979477177.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:40:20,655] Trial 45 finished with value: 0.7890898297538533 and parameters: {'max_df': 0.7184746557556797, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 17063, 'extra_features_weight_factor': 3, 'C': 0.08068105384625134, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 562}. Best is trial 39 with value: 0.8086903979477177.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:44:56,183] Trial 46 finished with value: 0.8086267941569317 and parameters: {'max_df': 0.7385543133325222, 'min_df': 4, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 16168, 'extra_features_weight_factor': 3, 'C': 0.9522805036520903, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 330}. Best is trial 39 with value: 0.8086903979477177.\n","[I 2024-02-14 10:49:24,331] Trial 47 finished with value: 0.7000657239171455 and parameters: {'max_df': 0.7380240686676922, 'min_df': 4, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 15165, 'extra_features_weight_factor': 3, 'C': 0.0003438420266052422, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 341}. Best is trial 39 with value: 0.8086903979477177.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 10:53:38,671] Trial 48 finished with value: 0.8100578794496152 and parameters: {'max_df': 0.7075074852832529, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 17339, 'extra_features_weight_factor': 3, 'C': 1.1926655328748625, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 300}. Best is trial 48 with value: 0.8100578794496152.\n","[I 2024-02-14 10:57:00,746] Trial 49 finished with value: 0.8064006614794241 and parameters: {'max_df': 0.7003589222167774, 'min_df': 4, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 17705, 'extra_features_weight_factor': 1, 'C': 5.677696322117042, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 396}. Best is trial 48 with value: 0.8100578794496152.\n"]}],"source":["def objective(trial):\n","    # TF-IDF parameters\n","    max_df = trial.suggest_float('max_df', 0.7, 0.95)\n","    min_df = trial.suggest_int('min_df', 1, 5)\n","    ngram_range = (1, trial.suggest_int('ngram_2', 2, 3))      \n","    norm = trial.suggest_categorical('norm', ['l1', 'l2'])\n","    smooth_idf = trial.suggest_categorical('smooth_idf', [True, False])\n","    sublinear_tf = trial.suggest_categorical('sublinear_tf', [True, False])\n","    max_features_tfidf = trial.suggest_int('max_features_tfidf', 10000, 20000)      \n","\n","    vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df, ngram_range=ngram_range, norm=norm, \n","                                 smooth_idf=smooth_idf, sublinear_tf=sublinear_tf, max_features=max_features_tfidf)\n","    \n","    extra_features_weight_factor = trial.suggest_categorical('extra_features_weight_factor', extra_features_weight_factors)\n","    extra_features = weighted_extra_features_sets[extra_features_weight_factor]\n","\n","    C = trial.suggest_float('C', 1e-5, 10.0, log=True)\n","    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n","    class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n","    solver = 'liblinear' if penalty == 'l1' else trial.suggest_categorical('solver', ['liblinear', 'saga'])\n","    max_iter = trial.suggest_int('max_iter', 100, 1000)\n","\n","    model = LogisticRegression(C=C, penalty=penalty, class_weight=class_weight, solver=solver, max_iter=max_iter, random_state=21, n_jobs=-1)\n","\n","    accuracy, _, _, _, _ = train_eval_model(model, X, y, vectorizer, extra_features, k=3)\n","    return accuracy \n"," \n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=50, show_progress_bar=True) "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T10:57:00.756962Z","iopub.status.busy":"2024-02-14T10:57:00.756578Z","iopub.status.idle":"2024-02-14T10:57:00.763337Z","shell.execute_reply":"2024-02-14T10:57:00.762178Z","shell.execute_reply.started":"2024-02-14T10:57:00.756927Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters for TF-IDF with Logistic Regression: {'max_df': 0.7075074852832529, 'min_df': 3, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 17339, 'extra_features_weight_factor': 3, 'C': 1.1926655328748625, 'penalty': 'l2', 'class_weight': None, 'solver': 'saga', 'max_iter': 300}\n"]}],"source":["best_params = study.best_params\n","print(\"Best parameters for TF-IDF with Logistic Regression:\", best_params)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T10:57:00.764848Z","iopub.status.busy":"2024-02-14T10:57:00.764485Z","iopub.status.idle":"2024-02-14T11:05:06.798591Z","shell.execute_reply":"2024-02-14T11:05:06.797518Z","shell.execute_reply.started":"2024-02-14T10:57:00.764822Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]}],"source":["vectorizer = TfidfVectorizer(max_df=best_params[\"max_df\"], min_df=best_params[\"min_df\"], ngram_range=(1, best_params[\"ngram_2\"]), norm=best_params[\"norm\"], \n","                                 smooth_idf=best_params[\"smooth_idf\"], sublinear_tf=best_params[\"sublinear_tf\"], max_features=best_params['max_features_tfidf'])\n","extra_features = weighted_extra_features_sets[best_params[\"extra_features_weight_factor\"]]\n","model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], class_weight=best_params['class_weight'], solver=best_params['solver'], max_iter=best_params['max_iter'], random_state=21, n_jobs=-1)\n","\n","mean_accuracy, mean_precision, mean_recall, mean_f1_score, total_time = train_eval_model(model, X, y, vectorizer, extra_features, k=5)\n","results.append({\"Method\": \"Logistic Regression with TF-IDF\", \"Accuracy\": mean_accuracy, \"Precision\": mean_precision, \"Recall\": mean_recall, \"F-Measure\": mean_f1_score})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LR_tf_idf_best_params = best_params"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T11:05:06.801631Z","iopub.status.busy":"2024-02-14T11:05:06.801308Z","iopub.status.idle":"2024-02-14T11:05:06.807824Z","shell.execute_reply":"2024-02-14T11:05:06.806947Z","shell.execute_reply.started":"2024-02-14T11:05:06.801604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression with TF-IDF:\n","- Accuracy: 0.81\n","- Precision: 0.80\n","- Recall: 0.79\n","- F1: 0.80\n","- Total Time: 77.23\n"]}],"source":["print(\"Logistic Regression with TF-IDF:\")\n","print(f\"- Accuracy: {mean_accuracy:.2f}\")\n","print(f\"- Precision: {mean_precision:.2f}\")\n","print(f\"- Recall: {mean_recall:.2f}\")\n","print(f\"- F1: {mean_f1_score:.2f}\")\n","print(f\"- Total Time: {total_time:.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# XGB with BoW"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T11:42:52.001984Z","iopub.status.busy":"2024-02-14T11:42:52.001154Z","iopub.status.idle":"2024-02-14T17:08:55.071784Z","shell.execute_reply":"2024-02-14T17:08:55.070829Z","shell.execute_reply.started":"2024-02-14T11:42:52.001952Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-02-14 11:42:52,008] A new study created in memory with name: no-name-e26fc725-90b4-4e32-b212-af17e27b0ef8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52f4eaa0d5494e49a52165a44f10e088","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[I 2024-02-14 11:48:11,125] Trial 0 finished with value: 0.8299658659656115 and parameters: {'max_df': 0.7665174882296566, 'min_df': 3, 'ngram_2': 3, 'bow_max_features': 10262, 'extra_features_weight_factor': 2, 'n_estimators': 444, 'max_depth': 9, 'learning_rate': 0.23434869459499993, 'subsample': 0.6420566055900587, 'colsample_bytree': 0.8572448756900397}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 11:51:45,546] Trial 1 finished with value: 0.8168422838001145 and parameters: {'max_df': 0.7047153605147536, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 11509, 'extra_features_weight_factor': 3, 'n_estimators': 167, 'max_depth': 8, 'learning_rate': 0.2314214085133344, 'subsample': 0.897912552947423, 'colsample_bytree': 0.33020763972702805}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 11:57:04,592] Trial 2 finished with value: 0.81790234697988 and parameters: {'max_df': 0.7093859397186328, 'min_df': 3, 'ngram_2': 4, 'bow_max_features': 12131, 'extra_features_weight_factor': 1, 'n_estimators': 489, 'max_depth': 4, 'learning_rate': 0.2958368599521675, 'subsample': 0.9768429672773917, 'colsample_bytree': 0.9034304521872971}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:01:47,403] Trial 3 finished with value: 0.7875739394067887 and parameters: {'max_df': 0.8666802143460204, 'min_df': 4, 'ngram_2': 3, 'bow_max_features': 19588, 'extra_features_weight_factor': 1, 'n_estimators': 369, 'max_depth': 3, 'learning_rate': 0.09168420291902349, 'subsample': 0.8830707812946959, 'colsample_bytree': 0.5932170315686105}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:05:54,836] Trial 4 finished with value: 0.8212415459961414 and parameters: {'max_df': 0.9391565859565775, 'min_df': 1, 'ngram_2': 3, 'bow_max_features': 11291, 'extra_features_weight_factor': 1.5, 'n_estimators': 386, 'max_depth': 7, 'learning_rate': 0.15561609621148886, 'subsample': 0.6680044713979842, 'colsample_bytree': 0.4151232450644376}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:13:08,625] Trial 5 finished with value: 0.8214005554731062 and parameters: {'max_df': 0.7758269802334162, 'min_df': 4, 'ngram_2': 4, 'bow_max_features': 18108, 'extra_features_weight_factor': 3, 'n_estimators': 573, 'max_depth': 5, 'learning_rate': 0.21335281080567362, 'subsample': 0.6940392412561058, 'colsample_bytree': 0.4072550502303793}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:16:02,619] Trial 6 finished with value: 0.7884325905823987 and parameters: {'max_df': 0.8104908394341434, 'min_df': 3, 'ngram_2': 2, 'bow_max_features': 16406, 'extra_features_weight_factor': 3, 'n_estimators': 252, 'max_depth': 3, 'learning_rate': 0.14394261234296638, 'subsample': 0.9657580022914973, 'colsample_bytree': 0.7277584824652745}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:20:27,869] Trial 7 finished with value: 0.8066338753789726 and parameters: {'max_df': 0.7593543326038155, 'min_df': 5, 'ngram_2': 4, 'bow_max_features': 11311, 'extra_features_weight_factor': 1.5, 'n_estimators': 376, 'max_depth': 3, 'learning_rate': 0.26193490125997826, 'subsample': 0.9242051923389714, 'colsample_bytree': 0.6360940889547363}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:26:50,298] Trial 8 finished with value: 0.8282591642461891 and parameters: {'max_df': 0.8559915296412225, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 14696, 'extra_features_weight_factor': 1, 'n_estimators': 597, 'max_depth': 7, 'learning_rate': 0.1849591678260928, 'subsample': 0.5726699737562967, 'colsample_bytree': 0.8554502056257698}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:31:32,973] Trial 9 finished with value: 0.8189412088960502 and parameters: {'max_df': 0.7532473830766997, 'min_df': 5, 'ngram_2': 3, 'bow_max_features': 19942, 'extra_features_weight_factor': 1.5, 'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.23726325142566107, 'subsample': 0.8771128362320764, 'colsample_bytree': 0.7144751097354557}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:40:01,022] Trial 10 finished with value: 0.8203086903979477 and parameters: {'max_df': 0.8941900166333345, 'min_df': 2, 'ngram_2': 3, 'bow_max_features': 13953, 'extra_features_weight_factor': 2, 'n_estimators': 469, 'max_depth': 10, 'learning_rate': 0.04984252141716766, 'subsample': 0.5420838140218613, 'colsample_bytree': 0.9975758251526111}. Best is trial 0 with value: 0.8299658659656115.\n","[I 2024-02-14 12:47:22,830] Trial 11 finished with value: 0.8319163822163801 and parameters: {'max_df': 0.8341614701388645, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 14680, 'extra_features_weight_factor': 2, 'n_estimators': 590, 'max_depth': 9, 'learning_rate': 0.17246761042389203, 'subsample': 0.5521664345718562, 'colsample_bytree': 0.8544571170923697}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 12:54:03,407] Trial 12 finished with value: 0.8287467933088812 and parameters: {'max_df': 0.819640770353784, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 13549, 'extra_features_weight_factor': 2, 'n_estimators': 488, 'max_depth': 10, 'learning_rate': 0.11103693983110685, 'subsample': 0.6364301259084393, 'colsample_bytree': 0.8371188902237774}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:01:21,322] Trial 13 finished with value: 0.8298386583840397 and parameters: {'max_df': 0.7788438474441458, 'min_df': 3, 'ngram_2': 2, 'bow_max_features': 16289, 'extra_features_weight_factor': 2, 'n_estimators': 532, 'max_depth': 9, 'learning_rate': 0.18676583886167805, 'subsample': 0.5022239143181026, 'colsample_bytree': 0.9831280966636115}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:05:35,660] Trial 14 finished with value: 0.8301142748107787 and parameters: {'max_df': 0.8483302010686147, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 10009, 'extra_features_weight_factor': 2, 'n_estimators': 430, 'max_depth': 9, 'learning_rate': 0.2747853200470238, 'subsample': 0.7718160968108678, 'colsample_bytree': 0.7768400299392474}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:07:41,877] Trial 15 finished with value: 0.8141709245871054 and parameters: {'max_df': 0.8562673549618035, 'min_df': 1, 'ngram_2': 2, 'bow_max_features': 12930, 'extra_features_weight_factor': 2, 'n_estimators': 116, 'max_depth': 8, 'learning_rate': 0.2974119235263868, 'subsample': 0.7914004108170621, 'colsample_bytree': 0.7532179324929218}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:12:38,091] Trial 16 finished with value: 0.8009413361036318 and parameters: {'max_df': 0.8929500434016686, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 16080, 'extra_features_weight_factor': 2, 'n_estimators': 285, 'max_depth': 9, 'learning_rate': 0.027893235289290663, 'subsample': 0.7835358929208305, 'colsample_bytree': 0.5437134050606727}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:20:03,756] Trial 17 finished with value: 0.8232026628787076 and parameters: {'max_df': 0.9398272894003623, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 17314, 'extra_features_weight_factor': 2, 'n_estimators': 539, 'max_depth': 8, 'learning_rate': 0.08538573915352964, 'subsample': 0.7341620894812758, 'colsample_bytree': 0.8039251682737228}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:24:48,974] Trial 18 finished with value: 0.8285877838319163 and parameters: {'max_df': 0.8034910054643841, 'min_df': 4, 'ngram_2': 2, 'bow_max_features': 10017, 'extra_features_weight_factor': 2, 'n_estimators': 415, 'max_depth': 10, 'learning_rate': 0.14799137174103777, 'subsample': 0.8218226371867967, 'colsample_bytree': 0.7671635359702776}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:29:44,609] Trial 19 finished with value: 0.820054275234804 and parameters: {'max_df': 0.898722982041466, 'min_df': 1, 'ngram_2': 3, 'bow_max_features': 18433, 'extra_features_weight_factor': 2, 'n_estimators': 306, 'max_depth': 6, 'learning_rate': 0.2730013778304954, 'subsample': 0.7412234629491791, 'colsample_bytree': 0.9356957822575513}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:33:07,003] Trial 20 finished with value: 0.8210507346237835 and parameters: {'max_df': 0.846772862490715, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 14880, 'extra_features_weight_factor': 2, 'n_estimators': 210, 'max_depth': 9, 'learning_rate': 0.19165761799524228, 'subsample': 0.5997702960858685, 'colsample_bytree': 0.6777898363017747}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:38:26,058] Trial 21 finished with value: 0.8278563402378781 and parameters: {'max_df': 0.8313108223237995, 'min_df': 3, 'ngram_2': 3, 'bow_max_features': 10644, 'extra_features_weight_factor': 2, 'n_estimators': 435, 'max_depth': 9, 'learning_rate': 0.25397001612325937, 'subsample': 0.6346974020983551, 'colsample_bytree': 0.8814122834666478}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:43:57,437] Trial 22 finished with value: 0.8270824941166494 and parameters: {'max_df': 0.7929499073183885, 'min_df': 3, 'ngram_2': 3, 'bow_max_features': 12637, 'extra_features_weight_factor': 2, 'n_estimators': 440, 'max_depth': 8, 'learning_rate': 0.21871734942290746, 'subsample': 0.6900229650507134, 'colsample_bytree': 0.8074731050384818}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:48:44,291] Trial 23 finished with value: 0.8272203023300189 and parameters: {'max_df': 0.7342145726739968, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 10057, 'extra_features_weight_factor': 2, 'n_estimators': 533, 'max_depth': 10, 'learning_rate': 0.27350449765077134, 'subsample': 0.5055211892505, 'colsample_bytree': 0.9160856286189535}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:52:55,880] Trial 24 finished with value: 0.8261284372548604 and parameters: {'max_df': 0.8773135244585811, 'min_df': 4, 'ngram_2': 2, 'bow_max_features': 12116, 'extra_features_weight_factor': 2, 'n_estimators': 348, 'max_depth': 9, 'learning_rate': 0.2061344574671629, 'subsample': 0.5679114864651282, 'colsample_bytree': 0.794512857252014}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 13:57:54,284] Trial 25 finished with value: 0.824633748171391 and parameters: {'max_df': 0.8370512785743067, 'min_df': 3, 'ngram_2': 3, 'bow_max_features': 10632, 'extra_features_weight_factor': 2, 'n_estimators': 466, 'max_depth': 7, 'learning_rate': 0.16687844022448248, 'subsample': 0.6162854709237048, 'colsample_bytree': 0.9388299036115595}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 14:01:56,091] Trial 26 finished with value: 0.8253651917654292 and parameters: {'max_df': 0.9178710430599191, 'min_df': 2, 'ngram_2': 2, 'bow_max_features': 13325, 'extra_features_weight_factor': 1.5, 'n_estimators': 331, 'max_depth': 8, 'learning_rate': 0.24846068744717553, 'subsample': 0.6656536305130596, 'colsample_bytree': 0.8510026419468808}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 14:08:49,293] Trial 27 finished with value: 0.829213221107978 and parameters: {'max_df': 0.7360933733841156, 'min_df': 1, 'ngram_2': 3, 'bow_max_features': 14085, 'extra_features_weight_factor': 1, 'n_estimators': 515, 'max_depth': 9, 'learning_rate': 0.11955197575580127, 'subsample': 0.7079904699415767, 'colsample_bytree': 0.6832190561619904}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 14:14:03,267] Trial 28 finished with value: 0.8282167617189985 and parameters: {'max_df': 0.7996146087379141, 'min_df': 3, 'ngram_2': 3, 'bow_max_features': 11852, 'extra_features_weight_factor': 3, 'n_estimators': 413, 'max_depth': 10, 'learning_rate': 0.2855687523664417, 'subsample': 0.8110352191389221, 'colsample_bytree': 0.559358377498958}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 14:20:15,503] Trial 29 finished with value: 0.8278139377106876 and parameters: {'max_df': 0.8237879648066208, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 10781, 'extra_features_weight_factor': 3, 'n_estimators': 574, 'max_depth': 7, 'learning_rate': 0.23464809792911664, 'subsample': 0.5532860199812154, 'colsample_bytree': 0.6217033755431557}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 14:29:08,538] Trial 30 finished with value: 0.8316195645260458 and parameters: {'max_df': 0.7845089459637461, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 15775, 'extra_features_weight_factor': 2, 'n_estimators': 598, 'max_depth': 8, 'learning_rate': 0.22178334731265545, 'subsample': 0.8414844956885406, 'colsample_bytree': 0.9572819558798928}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 14:37:36,408] Trial 31 finished with value: 0.8306019038734709 and parameters: {'max_df': 0.7845910772431426, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 15510, 'extra_features_weight_factor': 2, 'n_estimators': 566, 'max_depth': 8, 'learning_rate': 0.23052153931012356, 'subsample': 0.8180895618953614, 'colsample_bytree': 0.9739216519055108}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 14:46:17,285] Trial 32 finished with value: 0.8304640956601014 and parameters: {'max_df': 0.7883321219387227, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 15644, 'extra_features_weight_factor': 2, 'n_estimators': 573, 'max_depth': 8, 'learning_rate': 0.2009296587074369, 'subsample': 0.8519215299987886, 'colsample_bytree': 0.9718542301689258}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 14:54:54,554] Trial 33 finished with value: 0.8301460767061717 and parameters: {'max_df': 0.7842800696067371, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 15544, 'extra_features_weight_factor': 2, 'n_estimators': 585, 'max_depth': 8, 'learning_rate': 0.1968224657661729, 'subsample': 0.8441876782546582, 'colsample_bytree': 0.9635395545513429}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 15:03:33,496] Trial 34 finished with value: 0.8297538533296585 and parameters: {'max_df': 0.7479080816823416, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 17024, 'extra_features_weight_factor': 2, 'n_estimators': 561, 'max_depth': 8, 'learning_rate': 0.17670068476860115, 'subsample': 0.8470056174824017, 'colsample_bytree': 0.8943331359848887}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 15:11:22,408] Trial 35 finished with value: 0.8266690694765408 and parameters: {'max_df': 0.767213583391361, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 15398, 'extra_features_weight_factor': 1, 'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.22049175498958737, 'subsample': 0.8966466052786032, 'colsample_bytree': 0.9471721530551015}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 15:18:43,546] Trial 36 finished with value: 0.8231178578243263 and parameters: {'max_df': 0.722619112033709, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 14621, 'extra_features_weight_factor': 2, 'n_estimators': 507, 'max_depth': 7, 'learning_rate': 0.12980198914624147, 'subsample': 0.92916428239187, 'colsample_bytree': 0.9994378984518517}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 15:27:02,269] Trial 37 finished with value: 0.8299022621748257 and parameters: {'max_df': 0.7931166845759677, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 15584, 'extra_features_weight_factor': 2, 'n_estimators': 550, 'max_depth': 8, 'learning_rate': 0.1666462951609963, 'subsample': 0.8258953164800398, 'colsample_bytree': 0.8889166536244267}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 15:35:52,353] Trial 38 finished with value: 0.8305276994508872 and parameters: {'max_df': 0.8138384954195754, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 16871, 'extra_features_weight_factor': 1.5, 'n_estimators': 563, 'max_depth': 8, 'learning_rate': 0.20541923776529572, 'subsample': 0.8690606001159857, 'colsample_bytree': 0.9262727601433302}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 15:42:32,253] Trial 39 finished with value: 0.8158564250429325 and parameters: {'max_df': 0.8177882198504938, 'min_df': 3, 'ngram_2': 4, 'bow_max_features': 17215, 'extra_features_weight_factor': 1.5, 'n_estimators': 501, 'max_depth': 4, 'learning_rate': 0.22552393942360274, 'subsample': 0.9388111203950724, 'colsample_bytree': 0.9020506879641763}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 15:50:11,181] Trial 40 finished with value: 0.8221319990671444 and parameters: {'max_df': 0.7672989515425139, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 18202, 'extra_features_weight_factor': 1.5, 'n_estimators': 553, 'max_depth': 5, 'learning_rate': 0.2422957623204699, 'subsample': 0.8755555827887417, 'colsample_bytree': 0.8465735631362705}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 15:58:54,567] Trial 41 finished with value: 0.8315347594716646 and parameters: {'max_df': 0.8130408918967663, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 16560, 'extra_features_weight_factor': 1.5, 'n_estimators': 573, 'max_depth': 8, 'learning_rate': 0.20364843970274618, 'subsample': 0.8507709418399926, 'colsample_bytree': 0.958654584480958}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 16:07:22,165] Trial 42 finished with value: 0.8262980473636229 and parameters: {'max_df': 0.8066137649272984, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 16869, 'extra_features_weight_factor': 1.5, 'n_estimators': 600, 'max_depth': 7, 'learning_rate': 0.20873893301597007, 'subsample': 0.9881020328483503, 'colsample_bytree': 0.9251234627196044}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 16:15:18,827] Trial 43 finished with value: 0.8250789747068925 and parameters: {'max_df': 0.8353117452556446, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 16644, 'extra_features_weight_factor': 1.5, 'n_estimators': 526, 'max_depth': 7, 'learning_rate': 0.16071380321734197, 'subsample': 0.9052324089961252, 'colsample_bytree': 0.9654603966817548}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 16:24:53,721] Trial 44 finished with value: 0.8310577310407701 and parameters: {'max_df': 0.8135457772834114, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 17652, 'extra_features_weight_factor': 1.5, 'n_estimators': 563, 'max_depth': 9, 'learning_rate': 0.17766765500916393, 'subsample': 0.8635400554111633, 'colsample_bytree': 0.879562001486263}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 16:32:33,242] Trial 45 finished with value: 0.8304852969236967 and parameters: {'max_df': 0.7728392816351859, 'min_df': 3, 'ngram_2': 4, 'bow_max_features': 17562, 'extra_features_weight_factor': 1.5, 'n_estimators': 487, 'max_depth': 9, 'learning_rate': 0.17527649179357227, 'subsample': 0.7596966685408159, 'colsample_bytree': 0.47988647798539047}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 16:41:30,837] Trial 46 finished with value: 0.8285029787775351 and parameters: {'max_df': 0.7582060159510338, 'min_df': 3, 'ngram_2': 4, 'bow_max_features': 18829, 'extra_features_weight_factor': 1.5, 'n_estimators': 466, 'max_depth': 9, 'learning_rate': 0.14700125479635578, 'subsample': 0.798493817958316, 'colsample_bytree': 0.8718526663239363}. Best is trial 11 with value: 0.8319163822163801.\n","[I 2024-02-14 16:51:09,543] Trial 47 finished with value: 0.8324040112790723 and parameters: {'max_df': 0.8660309985567956, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 16162, 'extra_features_weight_factor': 3, 'n_estimators': 570, 'max_depth': 10, 'learning_rate': 0.18172555976981955, 'subsample': 0.9071501181763212, 'colsample_bytree': 0.8300003853589302}. Best is trial 47 with value: 0.8324040112790723.\n","[I 2024-02-14 16:59:41,002] Trial 48 finished with value: 0.8304322937647084 and parameters: {'max_df': 0.8684032375388318, 'min_df': 1, 'ngram_2': 4, 'bow_max_features': 17825, 'extra_features_weight_factor': 3, 'n_estimators': 583, 'max_depth': 10, 'learning_rate': 0.1344811517586678, 'subsample': 0.9055729152308056, 'colsample_bytree': 0.3119989906694445}. Best is trial 47 with value: 0.8324040112790723.\n","[I 2024-02-14 17:08:55,064] Trial 49 finished with value: 0.8328280365509785 and parameters: {'max_df': 0.8806869371783079, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 16276, 'extra_features_weight_factor': 3, 'n_estimators': 547, 'max_depth': 10, 'learning_rate': 0.1821439563726806, 'subsample': 0.9474658762043557, 'colsample_bytree': 0.8229953057814048}. Best is trial 49 with value: 0.8328280365509785.\n"]}],"source":["def objective(trial):\n","    # Bow parameters\n","    max_df = trial.suggest_float('max_df', 0.7, 0.95)\n","    min_df = trial.suggest_int('min_df', 1, 5)  \n","    ngram_range = (1, trial.suggest_int('ngram_2', 2, 4))   \n","    bow_max_features = trial.suggest_int('bow_max_features', 10000, 20000)      \n","    vectorizer = CountVectorizer(max_df=max_df, min_df=min_df, ngram_range=ngram_range, max_features=bow_max_features)\n","\n","    extra_features_weight_factor = trial.suggest_categorical('extra_features_weight_factor', extra_features_weight_factors)\n","    extra_features = weighted_extra_features_sets[extra_features_weight_factor]\n","\n","    param = {\n","        'objective': 'binary:logistic',  \n","        'n_estimators': trial.suggest_int('n_estimators', 100, 600),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n","        'subsample': trial.suggest_float('subsample', 0.5, 1),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1),\n","        'n_jobs': -1,\n","    }\n","\n","    accuracy, _, _, _, _ = train_eval_model(None, X, y, vectorizer, extra_features, 3, param)\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=50, show_progress_bar=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:08:55.073940Z","iopub.status.busy":"2024-02-14T17:08:55.073662Z","iopub.status.idle":"2024-02-14T17:08:55.079296Z","shell.execute_reply":"2024-02-14T17:08:55.078378Z","shell.execute_reply.started":"2024-02-14T17:08:55.073915Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters for BoW with XGBooster: {'max_df': 0.8806869371783079, 'min_df': 2, 'ngram_2': 4, 'bow_max_features': 16276, 'extra_features_weight_factor': 3, 'n_estimators': 547, 'max_depth': 10, 'learning_rate': 0.1821439563726806, 'subsample': 0.9474658762043557, 'colsample_bytree': 0.8229953057814048}\n"]}],"source":["best_params = study.best_params\n","print(\"Best parameters for BoW with XGBooster:\", best_params)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:08:55.081242Z","iopub.status.busy":"2024-02-14T17:08:55.080642Z","iopub.status.idle":"2024-02-14T17:18:20.619121Z","shell.execute_reply":"2024-02-14T17:18:20.617989Z","shell.execute_reply.started":"2024-02-14T17:08:55.081207Z"},"trusted":true},"outputs":[],"source":["vectorizer = CountVectorizer(max_df=best_params[\"max_df\"], min_df=best_params[\"min_df\"], ngram_range=(1, best_params[\"ngram_2\"]), max_features=best_params[\"bow_max_features\"])\n","extra_features = weighted_extra_features_sets[best_params[\"extra_features_weight_factor\"]]\n","param = {\n","    'objective': 'binary:logistic',  \n","    'n_estimators': best_params['n_estimators'],\n","    'max_depth': best_params['max_depth'],\n","    'learning_rate': best_params['learning_rate'],\n","    'subsample': best_params['subsample'],\n","    'colsample_bytree': best_params['colsample_bytree'],\n","    'n_jobs': -1,\n","}\n","\n","mean_accuracy, mean_precision, mean_recall, mean_f1_score, total_time = train_eval_model(None, X, y, vectorizer, extra_features, 5, param)\n","results.append({\"Method\": \"XGBooster with BoW\", \"Accuracy\": mean_accuracy, \"Precision\": mean_precision, \"Recall\": mean_recall, \"F-Measure\": mean_f1_score})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["XGB_BoW_best_params = best_params"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:18:20.622947Z","iopub.status.busy":"2024-02-14T17:18:20.621773Z","iopub.status.idle":"2024-02-14T17:18:20.636157Z","shell.execute_reply":"2024-02-14T17:18:20.634315Z","shell.execute_reply.started":"2024-02-14T17:18:20.622904Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["XGBooster Model with BoW:\n","- Accuracy: 0.83\n","- Precision: 0.82\n","- Recall: 0.82\n","- F1: 0.82\n","- Total Time: 141.58\n"]}],"source":["print(\"XGBooster Model with BoW:\")\n","print(f\"- Accuracy: {mean_accuracy:.2f}\")\n","print(f\"- Precision: {mean_precision:.2f}\")\n","print(f\"- Recall: {mean_recall:.2f}\")\n","print(f\"- F1: {mean_f1_score:.2f}\")\n","print(f\"- Total Time: {total_time:.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# XGB with TF-IDF"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T15:13:39.774667Z","iopub.status.busy":"2024-02-17T15:13:39.774067Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-02-17 15:13:39,781] A new study created in memory with name: no-name-87b32033-d072-4986-8c57-c14cea2bd725\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f6140a5384548388f0bbfd8c8b5f2e5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[I 2024-02-17 15:30:34,971] Trial 0 finished with value: 0.8203192910297453 and parameters: {'max_df': 0.731377952188161, 'min_df': 1, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 10759, 'extra_features_weight_factor': 3, 'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.17925346690025834, 'subsample': 0.6152894413906231, 'colsample_bytree': 0.7565823793228494}. Best is trial 0 with value: 0.8203192910297453.\n","[I 2024-02-17 15:45:04,824] Trial 1 finished with value: 0.8146055504908093 and parameters: {'max_df': 0.7161070165383437, 'min_df': 5, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 12327, 'extra_features_weight_factor': 3, 'n_estimators': 435, 'max_depth': 5, 'learning_rate': 0.1343715561875565, 'subsample': 0.9246878222422912, 'colsample_bytree': 0.7409376466567301}. Best is trial 0 with value: 0.8203192910297453.\n","[I 2024-02-17 16:05:16,536] Trial 2 finished with value: 0.8227574363432061 and parameters: {'max_df': 0.7575181287244209, 'min_df': 3, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 12153, 'extra_features_weight_factor': 1, 'n_estimators': 348, 'max_depth': 9, 'learning_rate': 0.13571688408808905, 'subsample': 0.5368396729070131, 'colsample_bytree': 0.6364556679862415}. Best is trial 2 with value: 0.8227574363432061.\n","[I 2024-02-17 16:12:52,236] Trial 3 finished with value: 0.8112875527381432 and parameters: {'max_df': 0.8595869042161194, 'min_df': 2, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 18099, 'extra_features_weight_factor': 3, 'n_estimators': 158, 'max_depth': 7, 'learning_rate': 0.19713392498478793, 'subsample': 0.9936940106896355, 'colsample_bytree': 0.4457674969999399}. Best is trial 2 with value: 0.8227574363432061.\n","[I 2024-02-17 16:32:36,938] Trial 4 finished with value: 0.8185807874149299 and parameters: {'max_df': 0.9454071095626726, 'min_df': 3, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 12260, 'extra_features_weight_factor': 1, 'n_estimators': 251, 'max_depth': 10, 'learning_rate': 0.08460772451223028, 'subsample': 0.8568550231197671, 'colsample_bytree': 0.31937024620905524}. Best is trial 2 with value: 0.8227574363432061.\n","[I 2024-02-17 16:42:03,229] Trial 5 finished with value: 0.8119129900142048 and parameters: {'max_df': 0.8467318959095761, 'min_df': 5, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': False, 'max_features_tfidf': 16589, 'extra_features_weight_factor': 3, 'n_estimators': 112, 'max_depth': 8, 'learning_rate': 0.21442075889243808, 'subsample': 0.6274245176692748, 'colsample_bytree': 0.935342127211253}. Best is trial 2 with value: 0.8227574363432061.\n","[I 2024-02-17 17:05:35,475] Trial 6 finished with value: 0.8244959399580215 and parameters: {'max_df': 0.8451982903852283, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 16607, 'extra_features_weight_factor': 1, 'n_estimators': 512, 'max_depth': 8, 'learning_rate': 0.11410761249305282, 'subsample': 0.9423226899221322, 'colsample_bytree': 0.4550621477691798}. Best is trial 6 with value: 0.8244959399580215.\n","[I 2024-02-17 17:48:31,264] Trial 7 finished with value: 0.831089532936163 and parameters: {'max_df': 0.8176047602882307, 'min_df': 3, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 16086, 'extra_features_weight_factor': 1, 'n_estimators': 549, 'max_depth': 10, 'learning_rate': 0.2310592935031146, 'subsample': 0.7920307771858204, 'colsample_bytree': 0.7901002748026245}. Best is trial 7 with value: 0.831089532936163.\n","[I 2024-02-17 18:37:11,684] Trial 8 finished with value: 0.8152945915576568 and parameters: {'max_df': 0.7962831903655652, 'min_df': 2, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 16123, 'extra_features_weight_factor': 1.5, 'n_estimators': 595, 'max_depth': 8, 'learning_rate': 0.03819053357534735, 'subsample': 0.6375634996415995, 'colsample_bytree': 0.9012229883431055}. Best is trial 7 with value: 0.831089532936163.\n","[I 2024-02-17 18:49:08,341] Trial 9 finished with value: 0.818517183624144 and parameters: {'max_df': 0.9122506081301872, 'min_df': 4, 'ngram_2': 3, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 17698, 'extra_features_weight_factor': 1, 'n_estimators': 194, 'max_depth': 9, 'learning_rate': 0.27578095198784985, 'subsample': 0.5579109748487063, 'colsample_bytree': 0.3497753653694537}. Best is trial 7 with value: 0.831089532936163.\n","[I 2024-02-17 19:01:30,807] Trial 10 finished with value: 0.8135242860474484 and parameters: {'max_df': 0.7875566742777507, 'min_df': 4, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 19928, 'extra_features_weight_factor': 2, 'n_estimators': 586, 'max_depth': 3, 'learning_rate': 0.2597225836269085, 'subsample': 0.7638411800656671, 'colsample_bytree': 0.629472958018851}. Best is trial 7 with value: 0.831089532936163.\n","[I 2024-02-17 19:17:44,621] Trial 11 finished with value: 0.8162062458922552 and parameters: {'max_df': 0.8731835275112415, 'min_df': 2, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 14519, 'extra_features_weight_factor': 1, 'n_estimators': 485, 'max_depth': 6, 'learning_rate': 0.09135086987385393, 'subsample': 0.802957454274923, 'colsample_bytree': 0.5167586619134988}. Best is trial 7 with value: 0.831089532936163.\n","[I 2024-02-17 19:44:06,852] Trial 12 finished with value: 0.8302520830241482 and parameters: {'max_df': 0.8157057409361969, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 14472, 'extra_features_weight_factor': 1, 'n_estimators': 509, 'max_depth': 8, 'learning_rate': 0.23615701118050914, 'subsample': 0.8779394802582499, 'colsample_bytree': 0.8449412107054947}. Best is trial 7 with value: 0.831089532936163.\n","[I 2024-02-17 20:14:38,394] Trial 13 finished with value: 0.8316725676850341 and parameters: {'max_df': 0.807877233403472, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 14392, 'extra_features_weight_factor': 2, 'n_estimators': 421, 'max_depth': 10, 'learning_rate': 0.2252546884269708, 'subsample': 0.847223280821702, 'colsample_bytree': 0.8154687245762434}. Best is trial 13 with value: 0.8316725676850341.\n","[I 2024-02-17 20:39:41,330] Trial 14 finished with value: 0.8282273623507961 and parameters: {'max_df': 0.7630295756038864, 'min_df': 1, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 13809, 'extra_features_weight_factor': 2, 'n_estimators': 354, 'max_depth': 10, 'learning_rate': 0.2971701016238061, 'subsample': 0.7092190938555982, 'colsample_bytree': 0.817649244355805}. Best is trial 13 with value: 0.8316725676850341.\n","[I 2024-02-17 20:52:07,872] Trial 15 finished with value: 0.8156974155659678 and parameters: {'max_df': 0.8934974059800718, 'min_df': 3, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 15536, 'extra_features_weight_factor': 2, 'n_estimators': 394, 'max_depth': 4, 'learning_rate': 0.23062304837653985, 'subsample': 0.8148388373005608, 'colsample_bytree': 0.9765455854122767}. Best is trial 13 with value: 0.8316725676850341.\n","[I 2024-02-17 21:11:02,749] Trial 16 finished with value: 0.8237220938367926 and parameters: {'max_df': 0.816254989196813, 'min_df': 4, 'ngram_2': 2, 'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'max_features_tfidf': 13494, 'extra_features_weight_factor': 1.5, 'n_estimators': 283, 'max_depth': 9, 'learning_rate': 0.16743984716396038, 'subsample': 0.7179260561258342, 'colsample_bytree': 0.7237106188589462}. Best is trial 13 with value: 0.8316725676850341.\n","[I 2024-02-17 21:31:20,181] Trial 17 finished with value: 0.8235842856234231 and parameters: {'max_df': 0.7740418799387347, 'min_df': 3, 'ngram_2': 3, 'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': True, 'max_features_tfidf': 17974, 'extra_features_weight_factor': 2, 'n_estimators': 451, 'max_depth': 6, 'learning_rate': 0.25842330284549375, 'subsample': 0.7713072568634225, 'colsample_bytree': 0.8261522736596754}. Best is trial 13 with value: 0.8316725676850341.\n","[I 2024-02-17 22:06:21,433] Trial 18 finished with value: 0.8334322725634448 and parameters: {'max_df': 0.8247885633014839, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 19777, 'extra_features_weight_factor': 2, 'n_estimators': 546, 'max_depth': 10, 'learning_rate': 0.19694488539952623, 'subsample': 0.8574307213675778, 'colsample_bytree': 0.5711394501156387}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-17 22:24:23,436] Trial 19 finished with value: 0.824665550066784 and parameters: {'max_df': 0.7384563548746664, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': False, 'max_features_tfidf': 19976, 'extra_features_weight_factor': 2, 'n_estimators': 413, 'max_depth': 7, 'learning_rate': 0.2004796121191545, 'subsample': 0.8772531881068385, 'colsample_bytree': 0.5840715810896543}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-17 22:47:15,777] Trial 20 finished with value: 0.8269128840078869 and parameters: {'max_df': 0.7020220751520158, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 18985, 'extra_features_weight_factor': 2, 'n_estimators': 372, 'max_depth': 9, 'learning_rate': 0.16522872553106704, 'subsample': 0.9329808782605171, 'colsample_bytree': 0.5546638120844196}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-17 23:21:17,219] Trial 21 finished with value: 0.8306549070324591 and parameters: {'max_df': 0.8272497707919494, 'min_df': 2, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 15178, 'extra_features_weight_factor': 2, 'n_estimators': 539, 'max_depth': 10, 'learning_rate': 0.23402823313725646, 'subsample': 0.8435331819992777, 'colsample_bytree': 0.6935036193121391}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-17 23:55:11,831] Trial 22 finished with value: 0.8318315771619988 and parameters: {'max_df': 0.806216560690925, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 10086, 'extra_features_weight_factor': 2, 'n_estimators': 554, 'max_depth': 10, 'learning_rate': 0.19395778578298012, 'subsample': 0.7133278860037461, 'colsample_bytree': 0.7904499067235453}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-18 00:23:40,144] Trial 23 finished with value: 0.8295100387983124 and parameters: {'max_df': 0.778679730865482, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 10365, 'extra_features_weight_factor': 2, 'n_estimators': 476, 'max_depth': 9, 'learning_rate': 0.18837836802445077, 'subsample': 0.7144005181751338, 'colsample_bytree': 0.895066646051849}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-18 00:55:01,525] Trial 24 finished with value: 0.8327114296012043 and parameters: {'max_df': 0.8038113334594491, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 11219, 'extra_features_weight_factor': 2, 'n_estimators': 556, 'max_depth': 10, 'learning_rate': 0.20811242432710012, 'subsample': 0.6671562960371767, 'colsample_bytree': 0.6680609210220593}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-18 01:19:13,269] Trial 25 finished with value: 0.8293510293213475 and parameters: {'max_df': 0.8319965049985385, 'min_df': 2, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 11160, 'extra_features_weight_factor': 2, 'n_estimators': 544, 'max_depth': 9, 'learning_rate': 0.14610003289065607, 'subsample': 0.6714202249324648, 'colsample_bytree': 0.48354898844992056}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-18 01:52:45,418] Trial 26 finished with value: 0.8309199228274005 and parameters: {'max_df': 0.7968365068777867, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 11474, 'extra_features_weight_factor': 1.5, 'n_estimators': 598, 'max_depth': 10, 'learning_rate': 0.202909689294075, 'subsample': 0.6748127578219363, 'colsample_bytree': 0.6634812913116493}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-18 02:10:52,745] Trial 27 finished with value: 0.8262238429410392 and parameters: {'max_df': 0.8797028014193387, 'min_df': 2, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 10118, 'extra_features_weight_factor': 2, 'n_estimators': 553, 'max_depth': 7, 'learning_rate': 0.17690744784767912, 'subsample': 0.568320385874575, 'colsample_bytree': 0.5826573804924707}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-18 02:27:42,797] Trial 28 finished with value: 0.8264676574723854 and parameters: {'max_df': 0.7514622696362642, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 12963, 'extra_features_weight_factor': 2, 'n_estimators': 470, 'max_depth': 8, 'learning_rate': 0.25581059198218736, 'subsample': 0.5929378036771733, 'colsample_bytree': 0.391832149690351}. Best is trial 18 with value: 0.8334322725634448.\n","[I 2024-02-18 02:56:11,113] Trial 29 finished with value: 0.8283969724595586 and parameters: {'max_df': 0.8490337546987872, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 10979, 'extra_features_weight_factor': 2, 'n_estimators': 507, 'max_depth': 9, 'learning_rate': 0.1619901430024806, 'subsample': 0.6707535035424611, 'colsample_bytree': 0.6910423816386503}. Best is trial 18 with value: 0.8334322725634448.\n"]}],"source":["def objective(trial):\n","    # TF-IDF parameters\n","    max_df = trial.suggest_float('max_df', 0.7, 0.95)\n","    min_df = trial.suggest_int('min_df', 1, 5)\n","    ngram_range = (1, trial.suggest_int('ngram_2', 2, 3))      \n","    norm = trial.suggest_categorical('norm', ['l1', 'l2'])\n","    smooth_idf = trial.suggest_categorical('smooth_idf', [True, False])\n","    sublinear_tf = trial.suggest_categorical('sublinear_tf', [True, False])\n","    max_features_tfidf = trial.suggest_int('max_features_tfidf', 10000, 20000)      \n","\n","    vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df, ngram_range=ngram_range, norm=norm, \n","                                 smooth_idf=smooth_idf, sublinear_tf=sublinear_tf, max_features=max_features_tfidf)\n","    \n","    extra_features_weight_factor = trial.suggest_categorical('extra_features_weight_factor', extra_features_weight_factors)\n","    extra_features = weighted_extra_features_sets[extra_features_weight_factor]\n","\n","    param = {\n","        'objective': 'binary:logistic',  \n","        'n_estimators': trial.suggest_int('n_estimators', 100, 600),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n","        'subsample': trial.suggest_float('subsample', 0.5, 1),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1),\n","        'n_jobs': -1,\n","    }\n","\n","    accuracy, _, _, _, _ = train_eval_model(None, X, y, vectorizer, extra_features, 3, param)\n","    return accuracy\n","\n","study = optuna.create_study(direction='maximize')   \n","study.optimize(objective, n_trials=50, show_progress_bar=True) "]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:47:40.501717Z","iopub.status.busy":"2024-02-18T10:47:40.501330Z","iopub.status.idle":"2024-02-18T10:47:40.507591Z","shell.execute_reply":"2024-02-18T10:47:40.506444Z","shell.execute_reply.started":"2024-02-18T10:47:40.501687Z"},"trusted":true},"outputs":[],"source":["# best_params = {'max_df': 0.8247885633014839, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 19777, 'extra_features_weight_factor': 2, 'n_estimators': 546, 'max_depth': 10, 'learning_rate': 0.19694488539952623, 'subsample': 0.8574307213675778, 'colsample_bytree': 0.5711394501156387}"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:47:43.690505Z","iopub.status.busy":"2024-02-18T10:47:43.690139Z","iopub.status.idle":"2024-02-18T10:47:43.695355Z","shell.execute_reply":"2024-02-18T10:47:43.694204Z","shell.execute_reply.started":"2024-02-18T10:47:43.690476Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters for TF-IDF with XGBooster: {'max_df': 0.8247885633014839, 'min_df': 1, 'ngram_2': 2, 'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'max_features_tfidf': 19777, 'extra_features_weight_factor': 2, 'n_estimators': 546, 'max_depth': 10, 'learning_rate': 0.19694488539952623, 'subsample': 0.8574307213675778, 'colsample_bytree': 0.5711394501156387}\n"]}],"source":["best_params = study.best_params\n","print(\"Best parameters for TF-IDF with XGBooster:\", best_params)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T10:48:24.745114Z","iopub.status.busy":"2024-02-18T10:48:24.744156Z","iopub.status.idle":"2024-02-18T11:24:02.873736Z","shell.execute_reply":"2024-02-18T11:24:02.872928Z","shell.execute_reply.started":"2024-02-18T10:48:24.745079Z"},"trusted":true},"outputs":[],"source":["vectorizer = TfidfVectorizer(max_df=best_params[\"max_df\"], min_df=best_params[\"min_df\"], ngram_range=(1, best_params[\"ngram_2\"]), norm=best_params[\"norm\"], \n","                                 smooth_idf=best_params[\"smooth_idf\"], sublinear_tf=best_params[\"sublinear_tf\"], max_features=best_params['max_features_tfidf'])\n","extra_features = weighted_extra_features_sets[best_params[\"extra_features_weight_factor\"]]\n","param = {\n","    'objective': 'binary:logistic',  \n","    'n_estimators': best_params['n_estimators'],\n","    'max_depth': best_params['max_depth'],\n","    'learning_rate': best_params['learning_rate'],\n","    'subsample': best_params['subsample'],\n","    'colsample_bytree': best_params['colsample_bytree'],\n","    'n_jobs': -1,\n","}\n","\n","mean_accuracy, mean_precision, mean_recall, mean_f1_score, total_time = train_eval_model(None, X, y, vectorizer, extra_features, 5, param)\n","results.append({\"Method\": \"XGBooster with TF-IDF\", \"Accuracy\": mean_accuracy, \"Precision\": mean_precision, \"Recall\": mean_recall, \"F-Measure\": mean_f1_score, \"Time\": total_time})"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T11:47:42.391040Z","iopub.status.busy":"2024-02-18T11:47:42.390637Z","iopub.status.idle":"2024-02-18T11:47:42.395478Z","shell.execute_reply":"2024-02-18T11:47:42.394566Z","shell.execute_reply.started":"2024-02-18T11:47:42.391010Z"},"trusted":true},"outputs":[],"source":["XGB_tf_idf_best_params = best_params"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T11:24:02.875583Z","iopub.status.busy":"2024-02-18T11:24:02.875293Z","iopub.status.idle":"2024-02-18T11:24:02.880831Z","shell.execute_reply":"2024-02-18T11:24:02.880001Z","shell.execute_reply.started":"2024-02-18T11:24:02.875548Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["XGBooster Model with TF-IDF:\n","- Accuracy: 0.83\n","- Precision: 0.82\n","- Recall: 0.82\n","- F1: 0.82\n","- Total Time: 700.15\n"]}],"source":["print(\"XGBooster Model with TF-IDF:\")\n","print(f\"- Accuracy: {mean_accuracy:.2f}\")\n","print(f\"- Precision: {mean_precision:.2f}\")\n","print(f\"- Recall: {mean_recall:.2f}\")\n","print(f\"- F1: {mean_f1_score:.2f}\")\n","print(f\"- Total Time: {total_time:.2f}\")"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T11:47:04.684931Z","iopub.status.busy":"2024-02-18T11:47:04.684058Z","iopub.status.idle":"2024-02-18T11:47:04.699765Z","shell.execute_reply":"2024-02-18T11:47:04.698736Z","shell.execute_reply.started":"2024-02-18T11:47:04.684897Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Method</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F-Measure</th>\n","      <th>Time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Logistic Regression with BoW</td>\n","      <td>0.81</td>\n","      <td>0.80</td>\n","      <td>0.80</td>\n","      <td>0.80</td>\n","      <td>60.37</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Logistic Regression with TF-IDF</td>\n","      <td>0.81</td>\n","      <td>0.80</td>\n","      <td>0.79</td>\n","      <td>0.80</td>\n","      <td>77.23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>XGBooster with BoW</td>\n","      <td>0.83</td>\n","      <td>0.82</td>\n","      <td>0.82</td>\n","      <td>0.82</td>\n","      <td>141.58</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>XGBooster with TF-IDF</td>\n","      <td>0.83</td>\n","      <td>0.82</td>\n","      <td>0.82</td>\n","      <td>0.82</td>\n","      <td>700.15</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            Method  Accuracy  Precision  Recall  F-Measure  \\\n","0     Logistic Regression with BoW      0.81       0.80    0.80       0.80   \n","1  Logistic Regression with TF-IDF      0.81       0.80    0.79       0.80   \n","2               XGBooster with BoW      0.83       0.82    0.82       0.82   \n","3            XGBooster with TF-IDF      0.83       0.82    0.82       0.82   \n","\n","     Time  \n","0   60.37  \n","1   77.23  \n","2  141.58  \n","3  700.15  "]},"metadata":{},"output_type":"display_data"}],"source":["results_df = pd.DataFrame(results)\n","display(results_df)"]},{"cell_type":"markdown","metadata":{},"source":["# Comments on Results"]},{"cell_type":"markdown","metadata":{},"source":["**Logistic Regression with BoW and TF-IDF**\n","* **BoW Configuration**: The optimal parameters for the Bag of Words (BoW) approach with Logistic Regression include a specific range for max_df and min_df, a bigram (ngram_2: 2), and a substantial number of features (bow_max_features: 19340). The inclusion of an extra_features_weight_factor of 3 indicates the model benefits from emphasizing additional features alongside the textual content. The regularization strength (C: 0.15042289892477853) and choice of solver as 'liblinear' suggest a model that balances complexity and computational efficiency, achieving solid performance across all metrics (Accuracy, Precision, Recall, F1) at 0.80, with a relatively quick total time of 60.37 seconds.\n","\n","* **TF-IDF Configuration**: The TF-IDF variant introduces slightly different parameters, with adjustments in max_df, min_df, and max_features_tfidf (17339), alongside TF-IDF specific parameters (norm: 'l2', smooth_idf: True, sublinear_tf: True). The extra_features_weight_factor remains at 3, underscoring the consistent value of additional features. The higher C value (1.1926655328748625) and use of the 'saga' solver indicate a preference for a more robust regularization approach, which maintains comparable performance metrics to the BoW model but with a slightly longer computation time (77.23 seconds).\n","\n","**XGBooster with BoW and TF-IDF**\n","* **BoW Configuration**: The XGBoost model with BoW features highlights an aggressive approach to feature selection and ensemble complexity (n_estimators: 547, max_depth: 10, learning_rate: 0.1821439563726806). The extra_features_weight_factor of 3 continues to play a significant role, enhancing model performance with an optimal mix of textual and additional features. This configuration leads to improved accuracy and F1 scores (0.83) compared to Logistic Regression at the cost of increased computational time (141.58 seconds).\n","\n","* **TF-IDF Configuration**: With TF-IDF, the XGBoost model adjusts its feature handling (max_features_tfidf: 19777) and slightly alters its ensemble strategy (n_estimators: 546, max_depth: 10). Notably, the extra_features_weight_factor is reduced to 2, possibly indicating a different valuation of additional features when combined with TF-IDF's normalized feature set. Despite these changes, performance metrics mirror those of the BoW configuration, but with a significant increase in computation time (700.15 seconds), suggesting a more complex model that is computationally intensive to train."]},{"cell_type":"markdown","metadata":{},"source":["**Feature Representation**: The results indicate that both Logistic Regression and XGBoost models achieve similar performance levels with BoW and TF-IDF representations\\\n","**Model Selection**: XGBoost shows a slight advantage over Logistic Regression in terms of accuracy and F1 scores, which could justify the additional computational resources required.\\\n","**Computational Efficiency**: The significant difference in training times, especially for the TF-IDF variant of XGBoost, highlights the trade-offs between computational efficiency and model performance."]},{"cell_type":"markdown","metadata":{},"source":["# Predictions on test dataset"]},{"cell_type":"markdown","metadata":{},"source":["Based on the score table we choose **XGBoost** with **TF-IDF** for our best model"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T12:24:05.759870Z","iopub.status.busy":"2024-02-18T12:24:05.759496Z","iopub.status.idle":"2024-02-18T12:24:05.770647Z","shell.execute_reply":"2024-02-18T12:24:05.769750Z","shell.execute_reply.started":"2024-02-18T12:24:05.759844Z"},"trusted":true},"outputs":[],"source":["class DuplicatesClassifier:\n","    def __init__(self, xgb_parameters, vectorizer, extra_features_weight_factor, extra_features_names):\n","        self.xgb_parameters = xgb_parameters\n","        self.vectorizer = vectorizer\n","        self.extra_features_weight_factor = extra_features_weight_factor\n","        self.extra_features_names = extra_features_names\n","        self.model = None\n","        self.q1_vectorizer = None\n","        self.q2_vectorizer = None\n","        \n","        \n","    def train(self, X, y):\n","        n_estimators = self.xgb_parameters.get('n_estimators') \n","        xgb_parameters = copy.deepcopy(self.xgb_parameters)\n","        xgb_parameters.pop('n_estimators')\n","\n","        self.q1_vectorizer = clone(self.vectorizer)\n","        self.q2_vectorizer = clone(self.vectorizer)\n","\n","        train_q1_vectors = self.q1_vectorizer.fit_transform(X['Question1'])\n","        train_q2_vectors = self.q2_vectorizer.fit_transform(X['Question2'])\n","        \n","        train_weighted_extra_features = X[self.extra_features_names] * self.extra_features_weight_factor\n","        train_weighted_extra_features = csr_matrix(train_weighted_extra_features.to_numpy())\n","\n","        X_train_combined = hstack([train_q1_vectors, train_q2_vectors, train_weighted_extra_features])\n","\n","        dtrain = xgb.DMatrix(X_train_combined, label=y)\n","        self.model = xgb.train(xgb_parameters, dtrain, num_boost_round=n_estimators, verbose_eval=False)\n","        \n","        \n","    def predict(self, X):\n","        test_q1_vectors = self.q1_vectorizer.transform(X['Question1'])\n","        test_q2_vectors = self.q2_vectorizer.transform(X['Question2'])\n","        \n","        test_weighted_extra_features = X[self.extra_features_names] * self.extra_features_weight_factor\n","        test_weighted_extra_features = csr_matrix(test_weighted_extra_features.to_numpy())\n","\n","        X_test_combined = hstack([test_q1_vectors, test_q2_vectors, test_weighted_extra_features])\n","\n","        dvalid = xgb.DMatrix(X_test_combined)\n","        preds = self.model.predict(dvalid)\n","        y_pred = np.rint(preds)\n","        \n","        return y_pred\n"]},{"cell_type":"markdown","metadata":{},"source":["Train duplicates_classifier"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T12:24:08.317515Z","iopub.status.busy":"2024-02-18T12:24:08.316802Z","iopub.status.idle":"2024-02-18T12:38:39.498356Z","shell.execute_reply":"2024-02-18T12:38:39.497333Z","shell.execute_reply.started":"2024-02-18T12:24:08.317487Z"},"trusted":true},"outputs":[],"source":["vectorizer = TfidfVectorizer(max_df=XGB_tf_idf_best_params[\"max_df\"], min_df=XGB_tf_idf_best_params[\"min_df\"], ngram_range=(1, XGB_tf_idf_best_params[\"ngram_2\"]), norm=XGB_tf_idf_best_params[\"norm\"], \n","                                 smooth_idf=XGB_tf_idf_best_params[\"smooth_idf\"], sublinear_tf=XGB_tf_idf_best_params[\"sublinear_tf\"], max_features=XGB_tf_idf_best_params['max_features_tfidf'])\n","\n","param = {\n","    'objective': 'binary:logistic',  \n","    'n_estimators': XGB_tf_idf_best_params['n_estimators'],\n","    'max_depth': XGB_tf_idf_best_params['max_depth'],\n","    'learning_rate': XGB_tf_idf_best_params['learning_rate'],\n","    'subsample': XGB_tf_idf_best_params['subsample'],\n","    'colsample_bytree': XGB_tf_idf_best_params['colsample_bytree'],\n","    'n_jobs': -1,\n","}\n","\n","extra_features_names = X.drop(columns=['Question1', 'Question2']).columns.tolist()\n","\n","duplicates_classifier = DuplicatesClassifier(param, vectorizer, XGB_tf_idf_best_params[\"extra_features_weight_factor\"], extra_features_names)\n","duplicates_classifier.train(X, y)\n"]},{"cell_type":"markdown","metadata":{},"source":["Predict labels for test dataset"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T12:38:39.500617Z","iopub.status.busy":"2024-02-18T12:38:39.500292Z","iopub.status.idle":"2024-02-18T12:38:50.220341Z","shell.execute_reply":"2024-02-18T12:38:50.219527Z","shell.execute_reply.started":"2024-02-18T12:38:39.500588Z"},"trusted":true},"outputs":[],"source":["X_test = test_df[test_df.drop(columns=['Id']).columns.tolist()]\n","y_pred = duplicates_classifier.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["We save the predictions separating the fields Id, Predicted with the comma (\",\") character specifying the article Id from the test set and the predicted label to indicate\n","whether the documents in the pair with the specified Id are similar or not"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T12:49:26.980738Z","iopub.status.busy":"2024-02-18T12:49:26.980044Z","iopub.status.idle":"2024-02-18T12:49:26.985639Z","shell.execute_reply":"2024-02-18T12:49:26.984654Z","shell.execute_reply.started":"2024-02-18T12:49:26.980705Z"},"trusted":true},"outputs":[],"source":["output_df = pd.DataFrame({'Id': test_df['Id'], 'Predicted': y_pred})"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T12:49:28.733471Z","iopub.status.busy":"2024-02-18T12:49:28.732530Z","iopub.status.idle":"2024-02-18T12:49:28.743407Z","shell.execute_reply":"2024-02-18T12:49:28.742558Z","shell.execute_reply.started":"2024-02-18T12:49:28.733438Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>283003</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>283004</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>283005</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>283006</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>283007</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>283008</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>283009</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>283010</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>283011</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>283012</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Id  Predicted\n","0  283003        0.0\n","1  283004        0.0\n","2  283005        1.0\n","3  283006        0.0\n","4  283007        0.0\n","5  283008        1.0\n","6  283009        0.0\n","7  283010        0.0\n","8  283011        0.0\n","9  283012        0.0"]},"metadata":{},"output_type":"display_data"}],"source":["display(output_df.head(10))"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T12:49:34.473906Z","iopub.status.busy":"2024-02-18T12:49:34.473508Z","iopub.status.idle":"2024-02-18T12:49:34.664259Z","shell.execute_reply":"2024-02-18T12:49:34.663471Z","shell.execute_reply.started":"2024-02-18T12:49:34.473878Z"},"trusted":true},"outputs":[],"source":["output_df.to_csv(PATH_TO_SAVE_RESULTS, index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4435456,"sourceId":7616050,"sourceType":"datasetVersion"},{"datasetId":4451591,"sourceId":7638488,"sourceType":"datasetVersion"},{"datasetId":4458470,"sourceId":7648427,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
