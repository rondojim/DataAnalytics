{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the BeautifulSoup package\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from src.preprocess import clean_html, clean_punctuation, clean_uppercase, clean_lemmatize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import distance\n",
    "from fuzzywuzzy import fuzz\n",
    "import nltk\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dimitriskpl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths to train, test datasets and to where the preprocessed train, test datasets will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TRAIN_DATA = \"../../bigdata2023duplicatedetection/q_3_2/data/train.csv\"\n",
    "PATH_TO_TEST_DATA = \"../../bigdata2023duplicatedetection/q_3_2/data/test_without_labels.csv\"\n",
    "\n",
    "# Path where the data will be saved after preprocessing and extracting features\n",
    "PATH_TO_PREPROCESSED_TRAIN_DATA = \"../../bigdata2023duplicatedetection/q_3_2/preprocessed_data/preprocessed_train_df.pkl\"\n",
    "PATH_TO_PREPROCESSED_TEST_DATA = \"../../bigdata2023duplicatedetection/q_3_2/preprocessed_data/preprocessed_test_df.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
    "test_df = pd.read_csv(PATH_TO_TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Question1</th>\n",
       "      <th>Question2</th>\n",
       "      <th>IsDuplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                          Question1  \\\n",
       "0   0  What is the step by step guide to invest in sh...   \n",
       "1   1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2  How can I increase the speed of my internet co...   \n",
       "3   3  Why am I mentally very lonely? How can I solve...   \n",
       "4   4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           Question2  IsDuplicate  \n",
       "0  What is the step by step guide to invest in sh...            0  \n",
       "1  What would happen if the Indian government sto...            0  \n",
       "2  How can Internet speed be increased by hacking...            0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...            0  \n",
       "4            Which fish would survive in salt water?            0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Question1</th>\n",
       "      <th>Question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283003</td>\n",
       "      <td>What can someone do if they've lost the wirele...</td>\n",
       "      <td>What is the best USB wireless mouse that can b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283004</td>\n",
       "      <td>Why India need to elect Prime minister?</td>\n",
       "      <td>Is prime minister of India elected or appointed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283005</td>\n",
       "      <td>How can I make money online with free of cost?</td>\n",
       "      <td>How can I make money online for free?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>283006</td>\n",
       "      <td>Does MDMA affect the first and higher order mo...</td>\n",
       "      <td>Do antipsychotics affect the first and higher ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283007</td>\n",
       "      <td>I am a Saudi National and have \"SR 3 million\" ...</td>\n",
       "      <td>Where should I invest money to get high returns?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                          Question1  \\\n",
       "0  283003  What can someone do if they've lost the wirele...   \n",
       "1  283004            Why India need to elect Prime minister?   \n",
       "2  283005     How can I make money online with free of cost?   \n",
       "3  283006  Does MDMA affect the first and higher order mo...   \n",
       "4  283007  I am a Saudi National and have \"SR 3 million\" ...   \n",
       "\n",
       "                                           Question2  \n",
       "0  What is the best USB wireless mouse that can b...  \n",
       "1   Is prime minister of India elected or appointed?  \n",
       "2              How can I make money online for free?  \n",
       "3  Do antipsychotics affect the first and higher ...  \n",
       "4   Where should I invest money to get high returns?  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Null values per column in train dataset\n",
      "Id             0\n",
      "Question1      0\n",
      "Question2      2\n",
      "IsDuplicate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total Null values per column in train dataset')\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row with Null values\n",
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Null values per column in test dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Id           0\n",
       "Question1    1\n",
       "Question2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total Null values per column in test dataset')\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates pairs: 105123 -> 37.15%\n",
      "Total non duplicates pairs: 177879 -> 62.85%\n"
     ]
    }
   ],
   "source": [
    "cnt_duplicdates = train_df[train_df['IsDuplicate'] == 1].shape[0]\n",
    "cnt_non_duplicdates = train_df[train_df['IsDuplicate'] == 0].shape[0]\n",
    "total_rows = train_df.shape[0]\n",
    "print(f\"Total duplicates pairs: {cnt_duplicdates} -> {(cnt_duplicdates/total_rows*100):.2f}%\")\n",
    "print(f\"Total non duplicates pairs: {cnt_non_duplicdates} -> {(cnt_non_duplicdates/total_rows*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we implement a more streamlined preprocessing approach to the data, aiming to retain as much potentially valuable information as possible for effectively comparing the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, modify_columns):\n",
    "    df = clean_html(df, modify_columns)\n",
    "    print(\"HTML clean done\")\n",
    "\n",
    "    df = clean_punctuation(df, modify_columns)\n",
    "    print(\"Punctation clean done\")\n",
    "\n",
    "    df = clean_uppercase(df, modify_columns)\n",
    "    print(\"Uppercase clean done\")\n",
    "\n",
    "    df = clean_lemmatize(df, modify_columns)\n",
    "    print(\"Lemmatize done\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML clean done\n",
      "Punctation clean done\n",
      "Uppercase clean done\n",
      "Lemmatize done\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocess(train_df, [\"Question1\", \"Question2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Null values with \"\"\n",
    "test_df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML clean done\n",
      "Punctation clean done\n",
      "Uppercase clean done\n",
      "Lemmatize done\n"
     ]
    }
   ],
   "source": [
    "test_df = preprocess(test_df, [\"Question1\", \"Question2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(numerator, denominator):\n",
    "    if denominator == 0:\n",
    "        return 0  \n",
    "    else:\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each pair of questions we extract new features:\n",
    "\n",
    "* **cwc_min**: The ratio of common non-stopwords to the total number of non-stopwords in the shorter question\n",
    "* **cwc_max**: The ratio of common non-stopwords to the total number of non-stopwords in the longer question\n",
    "* **csc_min**: The ration of common stopwords between the questions considering the shorter question\n",
    "* **csc_max**: The ration of common stopwords between the questions considering the longer question\n",
    "* **ctc_min**: The ratio of common tokens (including stopwords) to the total tokens in the shorter question\n",
    "* **ctc_max**: The ratio of common tokens (including stopwords) to the total tokens in the longer question\n",
    "* **last_word_eq**: Last word of both question is same or not\n",
    "* **first_word_eq**: First word of both question is same or not\n",
    "* **abs_len_diff**: Absolute difference of the number of words\n",
    "* **mean_len**: Average Token Length of both Questions\n",
    "* **jaccard_sim**: Jaccard similarity\n",
    "* **word_overlap**: Total common words \n",
    "* **share_n_grams**: Total shared 2-grams and 3-grams\n",
    "* **n_words_diff**: Difference of number of words \n",
    "* **token_set_ratio**: Compares the unordered token sets of both questions to measure similarity\n",
    "* **token_sort_ratio**: Compares the token sequences after sorting\n",
    "* **fuzz_ratio**: A simple ratio of similarity between the two question strings, considering the sequence of characters\n",
    "* **fuzz_partial_ratio**: Compares the similarity of partial strings\n",
    "* **longest_substr_ratio**: The ratio of the length of the longest common substring to the length of the shorter question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_features(q1, q2, stopwords):\n",
    "    token_features = [0.0]*16\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = word_tokenize(q1)\n",
    "    q2_tokens = word_tokenize(q2)\n",
    "\n",
    "    if not q1_tokens or not q2_tokens:\n",
    "        return token_features\n",
    "    \n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in stopwords])\n",
    "    q2_words = set([word for word in q2_tokens if word not in stopwords])\n",
    "    \n",
    "    # Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in stopwords])\n",
    "    q2_stops = set([word for word in q2_tokens if word in stopwords])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    # The ratio of common non-stopwords to the total number of non-stopwords in the shorter question\n",
    "    token_features[0] = safe_divide(common_word_count, min(len(q1_words), len(q2_words)))\n",
    "\n",
    "    # The ratio of common non-stopwords to the total number of non-stopwords in the longer question\n",
    "    token_features[1] = safe_divide(common_word_count, max(len(q1_words), len(q2_words)))\n",
    "\n",
    "    # The ration of common stopwords between the questions considering the shorter question\n",
    "    token_features[2] = safe_divide(common_stop_count, min(len(q1_stops), len(q2_stops)))\n",
    "\n",
    "    # The ration of common stopwords between the questions considering the longer question\n",
    "    token_features[3] = safe_divide(common_stop_count, max(len(q1_stops), len(q2_stops)))\n",
    "\n",
    "    # The ratio of common tokens (including stopwords) to the total tokens in the shorter question\n",
    "    token_features[4] = safe_divide(common_token_count, min(len(q1_tokens), len(q2_tokens)))\n",
    "\n",
    "    # The ratio of common tokens (including stopwords) to the total tokens in the longer question\n",
    "    token_features[5] = safe_divide(common_token_count, max(len(q1_tokens), len(q2_tokens)))\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    # Absolute difference of the number of words\n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    # Average Token Length of both Questions\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "\n",
    "    # jaccard similarity\n",
    "    token_features[10] = safe_divide(common_word_count, len(q1_words.union(q2_words)))\n",
    "\n",
    "    # total common words \n",
    "    token_features[11] = common_word_count\n",
    "\n",
    "    # total shared 2-grams and 3-grams\n",
    "    n_grams_q1 = set(ngrams(q1_tokens, 2)) | set(ngrams(q1_tokens, 3))\n",
    "    n_grams_q2 = set(ngrams(q2_tokens, 2)) | set(ngrams(q2_tokens, 3))\n",
    "    token_features[12] = len(n_grams_q1.intersection(n_grams_q2))\n",
    "\n",
    "    # difference of number of words\n",
    "    token_features[13] = abs(len(q1_words) - len(q2_words))\n",
    "\n",
    "    return token_features\n",
    "\n",
    "# returns the Longest Common sub string\n",
    "def get_longest_substr_ratio(a, b):\n",
    "    strs = list(distance.lcsubstrings(a, b))     \n",
    "    if len(strs) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n",
    "\n",
    "def extract_features(df):\n",
    "    token_features = df.apply(lambda x: get_token_features(x[\"Question1\"], x[\"Question2\"], stopwords.words(\"english\")), axis=1)\n",
    "    df[\"cwc_min\"] = list(map(lambda x: x[0], token_features))\n",
    "    df[\"cwc_max\"] = list(map(lambda x: x[1], token_features))\n",
    "    df[\"csc_min\"] = list(map(lambda x: x[2], token_features))\n",
    "    df[\"csc_max\"] = list(map(lambda x: x[3], token_features))\n",
    "    df[\"ctc_min\"] = list(map(lambda x: x[4], token_features))\n",
    "    df[\"ctc_max\"] = list(map(lambda x: x[5], token_features))\n",
    "    df[\"last_word_eq\"] = list(map(lambda x: x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
    "    df[\"abs_len_diff\"] = list(map(lambda x: x[8], token_features))\n",
    "    df[\"mean_len\"] = list(map(lambda x: x[9], token_features))\n",
    "    df[\"jaccard_sim\"] = list(map(lambda x: x[10], token_features))\n",
    "    df[\"word_overlap\"] = list(map(lambda x: x[11], token_features)) \n",
    "    df[\"share_n_grams\"] = list(map(lambda x: x[12], token_features)) \n",
    "    df[\"n_words_diff\"] = list(map(lambda x: x[13], token_features)) \n",
    "    df[\"token_set_ratio\"] = df.apply(lambda x: fuzz.token_set_ratio(x[\"Question1\"], x[\"Question2\"]), axis=1) # Compares the unordered token sets of both questions to measure similarity\n",
    "    df[\"token_sort_ratio\"] = df.apply(lambda x: fuzz.token_sort_ratio(x[\"Question1\"], x[\"Question2\"]), axis=1) # Compares the token sequences after sorting\n",
    "    df[\"fuzz_ratio\"] = df.apply(lambda x: fuzz.QRatio(x[\"Question1\"], x[\"Question2\"]), axis=1) # A simple ratio of similarity between the two question strings, considering the sequence of characters\n",
    "    df[\"fuzz_partial_ratio\"] = df.apply(lambda x: fuzz.partial_ratio(x[\"Question1\"], x[\"Question2\"]), axis=1) # Compares the similarity of partial strings\n",
    "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"Question1\"], x[\"Question2\"]), axis=1) # The ratio of the length of the longest common substring to the length of the shorter question\n",
    "    return df\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = extract_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = extract_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Question1</th>\n",
       "      <th>Question2</th>\n",
       "      <th>IsDuplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>word_overlap</th>\n",
       "      <th>share_n_grams</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what be the step by step guide to invest in sh...</td>\n",
       "      <td>what be the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>what be the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government ste...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increase by hack thr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>why be i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math be divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>0.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>55</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                          Question1  \\\n",
       "0   0  what be the step by step guide to invest in sh...   \n",
       "1   1     what be the story of kohinoor kohinoor diamond   \n",
       "2   2  how can i increase the speed of my internet co...   \n",
       "3   3   why be i mentally very lonely how can i solve it   \n",
       "4   4  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           Question2  IsDuplicate   cwc_min  \\\n",
       "0  what be the step by step guide to invest in sh...            0  1.000000   \n",
       "1  what would happen if the indian government ste...            0  0.666667   \n",
       "2  how can internet speed be increase by hack thr...            0  0.600000   \n",
       "3  find the remainder when math2324math be divide...            0  0.000000   \n",
       "4             which fish would survive in salt water            0  0.400000   \n",
       "\n",
       "    cwc_max   csc_min   csc_max   ctc_min   ctc_max  ...  mean_len  \\\n",
       "0  0.833333  1.000000  1.000000  0.916667  0.785714  ...      13.0   \n",
       "1  0.250000  0.666667  0.500000  0.500000  0.307692  ...      10.5   \n",
       "2  0.500000  0.400000  0.250000  0.500000  0.357143  ...      12.0   \n",
       "3  0.000000  0.250000  0.142857  0.111111  0.090909  ...      10.0   \n",
       "4  0.200000  1.000000  0.666667  0.571429  0.307692  ...      10.0   \n",
       "\n",
       "   jaccard_sim  word_overlap  share_n_grams  n_words_diff  token_set_ratio  \\\n",
       "0     0.833333           5.0           21.0           1.0              100   \n",
       "1     0.222222           2.0            3.0           5.0               81   \n",
       "2     0.375000           3.0            1.0           1.0               73   \n",
       "3     0.000000           0.0            0.0           2.0               28   \n",
       "4     0.153846           2.0            0.0           5.0               67   \n",
       "\n",
       "   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0                93          93                 100              0.982456  \n",
       "1                60          62                  72              0.553191  \n",
       "2                63          37                  44              0.181818  \n",
       "3                25          20                  26              0.081633  \n",
       "4                47          36                  55              0.153846  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing columns to numeric type\n",
    "num_cols = train_df.drop(columns=['Id', 'Question1', 'Question2']).columns\n",
    "for i in num_cols:\n",
    "    train_df[i] = train_df[i].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Question1</th>\n",
       "      <th>Question2</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>word_overlap</th>\n",
       "      <th>share_n_grams</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283003</td>\n",
       "      <td>what can someone do if theyve lose the wireles...</td>\n",
       "      <td>what be the best usb wireless mouse that can b...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283004</td>\n",
       "      <td>why india need to elect prime minister</td>\n",
       "      <td>be prime minister of india elect or appoint</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283005</td>\n",
       "      <td>how can i make money online with free of cost</td>\n",
       "      <td>how can i make money online for free</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>283006</td>\n",
       "      <td>do mdma affect the first and high order moment...</td>\n",
       "      <td>do antipsychotic affect the first and high ord...</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97</td>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>0.919192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283007</td>\n",
       "      <td>i be a saudi national and have sr 3 million in...</td>\n",
       "      <td>where should i invest money to get high return</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                          Question1  \\\n",
       "0  283003  what can someone do if theyve lose the wireles...   \n",
       "1  283004             why india need to elect prime minister   \n",
       "2  283005      how can i make money online with free of cost   \n",
       "3  283006  do mdma affect the first and high order moment...   \n",
       "4  283007  i be a saudi national and have sr 3 million in...   \n",
       "\n",
       "                                           Question2   cwc_min   cwc_max  \\\n",
       "0  what be the best usb wireless mouse that can b...  0.428571  0.333333   \n",
       "1        be prime minister of india elect or appoint  0.800000  0.800000   \n",
       "2               how can i make money online for free  1.000000  0.800000   \n",
       "3  do antipsychotic affect the first and high ord...  0.909091  0.909091   \n",
       "4     where should i invest money to get high return  0.200000  0.062500   \n",
       "\n",
       "   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  ...  mean_len  \\\n",
       "0     0.50  0.444444  0.411765  0.388889           0.0  ...      17.5   \n",
       "1     0.00  0.000000  0.571429  0.500000           0.0  ...       7.5   \n",
       "2     0.75  0.600000  0.875000  0.700000           0.0  ...       9.0   \n",
       "3     1.00  1.000000  0.944444  0.944444           1.0  ...      18.0   \n",
       "4     0.50  0.181818  0.333333  0.103448           0.0  ...      19.0   \n",
       "\n",
       "   jaccard_sim  word_overlap  share_n_grams  n_words_diff  token_set_ratio  \\\n",
       "0     0.230769           3.0            0.0           2.0               67   \n",
       "1     0.666667           4.0            1.0           0.0               81   \n",
       "2     0.800000           4.0            9.0           1.0               94   \n",
       "3     0.833333          10.0           29.0           0.0               97   \n",
       "4     0.050000           1.0            0.0          11.0               39   \n",
       "\n",
       "   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0                49          46                  45              0.131579  \n",
       "1                67          40                  42              0.384615  \n",
       "2                84          81                  89              0.756757  \n",
       "3                91          93                  94              0.919192  \n",
       "4                35          24                  39              0.170213  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beacause some features are on different scale,we use MinMaxScaler for each one of them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = [\"abs_len_diff\", \"mean_len\", \"word_overlap\", \"share_n_grams\", \"n_words_diff\", \"token_set_ratio\", \"token_sort_ratio\", \"fuzz_ratio\", \"fuzz_partial_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaler_dict = {}\n",
    "for feature_to_scale in features_to_scale:\n",
    "   scaler = MinMaxScaler()\n",
    "   train_df[feature_to_scale] = scaler.fit_transform(train_df[feature_to_scale].values.reshape(-1, 1))\n",
    "   test_df[feature_to_scale] = scaler.transform(test_df[feature_to_scale].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Question1</th>\n",
       "      <th>Question2</th>\n",
       "      <th>IsDuplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>word_overlap</th>\n",
       "      <th>share_n_grams</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what be the step by step guide to invest in sh...</td>\n",
       "      <td>what be the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.244186</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>what be the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government ste...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increase by hack thr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>why be i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math be divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                          Question1  \\\n",
       "0   0  what be the step by step guide to invest in sh...   \n",
       "1   1     what be the story of kohinoor kohinoor diamond   \n",
       "2   2  how can i increase the speed of my internet co...   \n",
       "3   3   why be i mentally very lonely how can i solve it   \n",
       "4   4  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           Question2  IsDuplicate   cwc_min  \\\n",
       "0  what be the step by step guide to invest in sh...            0  1.000000   \n",
       "1  what would happen if the indian government ste...            0  0.666667   \n",
       "2  how can internet speed be increase by hack thr...            0  0.600000   \n",
       "3  find the remainder when math2324math be divide...            0  0.000000   \n",
       "4             which fish would survive in salt water            0  0.400000   \n",
       "\n",
       "    cwc_max   csc_min   csc_max   ctc_min   ctc_max  ...  mean_len  \\\n",
       "0  0.833333  1.000000  1.000000  0.916667  0.785714  ...  0.096296   \n",
       "1  0.250000  0.666667  0.500000  0.500000  0.307692  ...  0.077778   \n",
       "2  0.500000  0.400000  0.250000  0.500000  0.357143  ...  0.088889   \n",
       "3  0.000000  0.250000  0.142857  0.111111  0.090909  ...  0.074074   \n",
       "4  0.200000  1.000000  0.666667  0.571429  0.307692  ...  0.074074   \n",
       "\n",
       "   jaccard_sim  word_overlap  share_n_grams  n_words_diff  token_set_ratio  \\\n",
       "0     0.833333      0.227273       0.244186      0.014925             1.00   \n",
       "1     0.222222      0.090909       0.034884      0.074627             0.81   \n",
       "2     0.375000      0.136364       0.011628      0.014925             0.73   \n",
       "3     0.000000      0.000000       0.000000      0.029851             0.28   \n",
       "4     0.153846      0.090909       0.000000      0.074627             0.67   \n",
       "\n",
       "   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0              0.93        0.93                1.00              0.982456  \n",
       "1              0.60        0.62                0.72              0.553191  \n",
       "2              0.63        0.37                0.44              0.181818  \n",
       "3              0.25        0.20                0.26              0.081633  \n",
       "4              0.47        0.36                0.55              0.153846  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Question1</th>\n",
       "      <th>Question2</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>word_overlap</th>\n",
       "      <th>share_n_grams</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283003</td>\n",
       "      <td>what can someone do if theyve lose the wireles...</td>\n",
       "      <td>what be the best usb wireless mouse that can b...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283004</td>\n",
       "      <td>why india need to elect prime minister</td>\n",
       "      <td>be prime minister of india elect or appoint</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283005</td>\n",
       "      <td>how can i make money online with free of cost</td>\n",
       "      <td>how can i make money online for free</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>283006</td>\n",
       "      <td>do mdma affect the first and high order moment...</td>\n",
       "      <td>do antipsychotic affect the first and high ord...</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.919192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283007</td>\n",
       "      <td>i be a saudi national and have sr 3 million in...</td>\n",
       "      <td>where should i invest money to get high return</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                          Question1  \\\n",
       "0  283003  what can someone do if theyve lose the wireles...   \n",
       "1  283004             why india need to elect prime minister   \n",
       "2  283005      how can i make money online with free of cost   \n",
       "3  283006  do mdma affect the first and high order moment...   \n",
       "4  283007  i be a saudi national and have sr 3 million in...   \n",
       "\n",
       "                                           Question2   cwc_min   cwc_max  \\\n",
       "0  what be the best usb wireless mouse that can b...  0.428571  0.333333   \n",
       "1        be prime minister of india elect or appoint  0.800000  0.800000   \n",
       "2               how can i make money online for free  1.000000  0.800000   \n",
       "3  do antipsychotic affect the first and high ord...  0.909091  0.909091   \n",
       "4     where should i invest money to get high return  0.200000  0.062500   \n",
       "\n",
       "   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  ...  mean_len  \\\n",
       "0     0.50  0.444444  0.411765  0.388889           0.0  ...  0.129630   \n",
       "1     0.00  0.000000  0.571429  0.500000           0.0  ...  0.055556   \n",
       "2     0.75  0.600000  0.875000  0.700000           0.0  ...  0.066667   \n",
       "3     1.00  1.000000  0.944444  0.944444           1.0  ...  0.133333   \n",
       "4     0.50  0.181818  0.333333  0.103448           0.0  ...  0.140741   \n",
       "\n",
       "   jaccard_sim  word_overlap  share_n_grams  n_words_diff  token_set_ratio  \\\n",
       "0     0.230769      0.136364       0.000000      0.029851             0.67   \n",
       "1     0.666667      0.181818       0.011628      0.000000             0.81   \n",
       "2     0.800000      0.181818       0.104651      0.014925             0.94   \n",
       "3     0.833333      0.454545       0.337209      0.000000             0.97   \n",
       "4     0.050000      0.045455       0.000000      0.164179             0.39   \n",
       "\n",
       "   token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0              0.49        0.46                0.45              0.131579  \n",
       "1              0.67        0.40                0.42              0.384615  \n",
       "2              0.84        0.81                0.89              0.756757  \n",
       "3              0.91        0.93                0.94              0.919192  \n",
       "4              0.35        0.24                0.39              0.170213  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the preprocessed datasets to the predefined paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(PATH_TO_PREPROCESSED_TRAIN_DATA)\n",
    "test_df.to_pickle(PATH_TO_PREPROCESSED_TEST_DATA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
